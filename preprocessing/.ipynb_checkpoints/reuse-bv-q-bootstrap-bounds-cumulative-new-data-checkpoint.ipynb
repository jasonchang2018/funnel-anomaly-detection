{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Outlier Removal\n",
    "## Title Function\n",
    "## Color logic\n",
    "    ##### PUT THE ABOVE INTO AN OVERARCHING FUNCTION - IT DOESN'T MAKE SENSE TO PULL THE DATA WITHIN THE GGPLOT CALL AND ALSO ON THE OUTSIDE CALL! MAKE THESE INDEPNEDENT FUNCTIONS THAT TAKE IN NUMERATOR/DENOMINATOR. MAKE THIS ON THE OUTSIDE SO ONLY NEED TO CHANGE THEM IN ONE PLACE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check.packages = function(pkg) {\n",
    "    new.pkg = pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n",
    "    if (length(new.pkg)) \n",
    "        install.packages(new.pkg, dependencies = TRUE)\n",
    "    sapply(pkg, require, character.only = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RPostgreSQL</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>RJDBC</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggplot2</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>dplyr</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>gridExtra</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>cowplot</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>rJava</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RPostgreSQL] TRUE\n",
       "\\item[RJDBC] TRUE\n",
       "\\item[ggplot2] TRUE\n",
       "\\item[dplyr] TRUE\n",
       "\\item[gridExtra] TRUE\n",
       "\\item[cowplot] TRUE\n",
       "\\item[rJava] TRUE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RPostgreSQL\n",
       ":   TRUERJDBC\n",
       ":   TRUEggplot2\n",
       ":   TRUEdplyr\n",
       ":   TRUEgridExtra\n",
       ":   TRUEcowplot\n",
       ":   TRUErJava\n",
       ":   TRUE\n",
       "\n"
      ],
      "text/plain": [
       "RPostgreSQL       RJDBC     ggplot2       dplyr   gridExtra     cowplot \n",
       "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
       "      rJava \n",
       "       TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check.packages(c('RPostgreSQL', 'RJDBC', 'ggplot2', 'dplyr', 'gridExtra', 'cowplot', 'rJava'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "options(scipen = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "killDbConnections = function () {\n",
    "  all_cons = dbListConnections(PostgreSQL())\n",
    "  print(all_cons)\n",
    "  for(con in all_cons)\n",
    "    +  dbDisconnect(con)\n",
    "  \n",
    "#   print(paste(length(all_cons), \" connections killed.\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "createReportingConnectionObject = function() {\n",
    "    \n",
    "    killDbConnections()\n",
    "    \n",
    "    drv = dbDriver('PostgreSQL')\n",
    "\n",
    "    reporting = dbConnect(\n",
    "      drv,\n",
    "      dbname = 'reporting',\n",
    "      host = 'reporting.ckpglb17yttu.us-east-1.rds.amazonaws.com',\n",
    "      port = 5432,\n",
    "      user = Sys.getenv('REPORTING_USER'),\n",
    "      password = Sys.getenv('REPORTING_PASS')\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkReportingConnection = function() {\n",
    "    \n",
    "    print(paste(length(dbListConnections(PostgreSQL())), \" connections active.\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getQueryString = function(date.string, ibv.provider) {\n",
    "    \n",
    "    if (is.na(ibv.provider)) {\n",
    "        \n",
    "        query.string = paste(\n",
    "            \"\n",
    "            with time_limit_gmt as \n",
    "            (\n",
    "              select\n",
    "                date_trunc('hour', min(createddate_)) as createddate_\n",
    "              from\n",
    "                (\n",
    "                  select\n",
    "                    max(createddate) as createddate_\n",
    "                  from\n",
    "                    cloudlending.application_status_history\n",
    "\n",
    "                  union all\n",
    "\n",
    "                  select\n",
    "                    max(createddate) as createddate_\n",
    "                  from\n",
    "                    cloudlending.applications\n",
    "                ) as latest_dates\n",
    "            )\n",
    "            select\n",
    "              (c_ash.createddate at time zone 'America/Chicago')::date as dayofyear\n",
    "              , extract(dow from c_ash.createddate at time zone 'America/Chicago') as dayofweek\n",
    "              , extract(hour from c_ash.createddate at time zone 'America/Chicago') as hourofday\n",
    "\n",
    "            --     , count(distinct case when new_value = 'NEW - ENTERED' then p_ap.loanid end) as newentered\n",
    "            --     , count(distinct case when c_ash.old_value = 'NEW - ENTERED' and c_ash.new_value = 'BUSINESS RULES PASSED' then p_ap.loanid end) as bizrulespassed\n",
    "\n",
    "              , count(distinct case when left(p_ap.denygrp,1) > '2' \n",
    "                                    then p_ap.loanid \n",
    "                                    end) as qualified\n",
    "\n",
    "              , count(distinct case when (c_ash.old_value = 'BANK VERIFICATION COMPLETED' and c_ash.new_value = 'NEW - SCORECARD GENERATED') or c_ash.new_value = 'BANK VERIFICATION COMPLETED'\n",
    "                                    then p_ap.loanid \n",
    "                                    end) as bankverified\n",
    "\n",
    "              , count(distinct case when c_ash.old_value = 'NEW - PRICING GENERATED' and c_ash.new_value in ('CONTRACT SIGNED', 'WAITING ON STIPULATIONS') \n",
    "                                    then p_ap.loanid \n",
    "                                    end) as passscorecardratecard\n",
    "\n",
    "              , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' \n",
    "                                    then p_ap.loanid \n",
    "                                    end) as contractsigned\n",
    "\n",
    "              , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' and left(p_ap.denygrp,1) not in ('4','5','8') \n",
    "                                    then p_ap.loanid \n",
    "                                    end) as cs_decisioned\n",
    "\n",
    "              , count(distinct case when left(p_ap.denygrp,1) = '9' \n",
    "                                    then p_ap.loanid \n",
    "                                    end) as funded\n",
    "\n",
    "              , case  when (c_ash.createddate at time zone 'America/Chicago')::date = '\", date.string, \"'::date \n",
    "                      then 'test' \n",
    "                      else 'training' \n",
    "                      end as grouping\n",
    "            from\n",
    "              public.all_allapps as p_ap\n",
    "              inner join\n",
    "                cloudlending.applications as c_app\n",
    "                on p_ap.loanid = c_app.name\n",
    "              inner join\n",
    "                cloudlending.application_status_history as c_ash\n",
    "                on c_app.id = c_ash.application\n",
    "              inner join\n",
    "                time_limit_gmt\n",
    "                on TRUE\n",
    "            where\n",
    "              c_app.createddate < createddate_\n",
    "              and c_ash.createddate < createddate_\n",
    "              and (c_ash.createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "              and p_ap.refi = 'N'\n",
    "            group by\n",
    "              dayofyear\n",
    "              , dayofweek\n",
    "              , hourofday\n",
    "              , grouping\n",
    "            order by\n",
    "              dayofyear asc\n",
    "              , hourofday asc\n",
    "            \",\n",
    "            sep = ''\n",
    "        )        \n",
    "    } else {\n",
    "        \n",
    "        query.string = paste(\n",
    "            \"\n",
    "            with time_limit_gmt as \n",
    "            (\n",
    "              select\n",
    "                date_trunc('hour', min(createddate_)) as createddate_\n",
    "              from\n",
    "                (\n",
    "                  select\n",
    "                    max(createddate) as createddate_\n",
    "                  from\n",
    "                    cloudlending.application_status_history\n",
    "\n",
    "                  union all\n",
    "\n",
    "                  select\n",
    "                    max(createddate) as createddate_\n",
    "                  from\n",
    "                    cloudlending.microbilt_information\n",
    "                ) as latest_dates\n",
    "            )\n",
    "            , qualified as\n",
    "            (\n",
    "              select\n",
    "                application\n",
    "                , min(createddate at time zone 'America/Chicago') as createddate_\n",
    "              from\n",
    "                cloudlending.application_status_history\n",
    "                inner join\n",
    "                  time_limit_gmt\n",
    "                  on TRUE\n",
    "              where\n",
    "                createddate < createddate_\n",
    "                and old_value = 'BUSINESS RULES PASSED'\n",
    "                and new_value = 'BUREAU APPROVED'\n",
    "              group by\n",
    "                application\n",
    "            )\n",
    "            , qualified_counts as\n",
    "            (\n",
    "              select\n",
    "                date_trunc('hour', createddate_) as q_time\n",
    "                , count(*) as q\n",
    "              from\n",
    "                qualified\n",
    "              group by\n",
    "                q_time\n",
    "            )\n",
    "            , bankverified as\n",
    "            (\n",
    "              select\n",
    "                c_ash.application\n",
    "                , min(c_ash.createddate at time zone 'America/Chicago') as createddate_\n",
    "              from\n",
    "                cloudlending.application_status_history as c_ash\n",
    "                inner join\n",
    "                  time_limit_gmt\n",
    "                  on TRUE\n",
    "                inner join\n",
    "                  (\n",
    "                    select\n",
    "                      application\n",
    "                    from\n",
    "                      (\n",
    "                        select\n",
    "                          *\n",
    "                          , row_number() over (partition by application order by createddate desc) as rn\n",
    "                        from\n",
    "                          cloudlending.microbilt_information\n",
    "                        inner join\n",
    "                          time_limit_gmt\n",
    "                          on TRUE\n",
    "                      where\n",
    "                        createddate < createddate_\n",
    "                      ) as c_mb\n",
    "                    where\n",
    "                      rn = 1\n",
    "                      and c_mb.ibv_source = '\", ibv.provider, \"'\n",
    "                  ) as c_mb\n",
    "                  on c_ash.application = c_mb.application\n",
    "              where\n",
    "                createddate < createddate_\n",
    "                and c_ash.new_value = 'BANK VERIFICATION COMPLETED'\n",
    "                or\n",
    "                  (\n",
    "                    c_ash.old_value = 'BANK VERIFICATION COMPLETED' \n",
    "                    and c_ash.new_value = 'NEW - SCORECARD GENERATED'\n",
    "                  )\n",
    "              group by\n",
    "                c_ash.application\n",
    "            )\n",
    "            , bankverified_counts as\n",
    "            (\n",
    "              select\n",
    "                date_trunc('hour', createddate_) as bv_time\n",
    "                , count(*) as bv\n",
    "              from\n",
    "                bankverified\n",
    "              group by\n",
    "                bv_time\n",
    "            )\n",
    "            select\n",
    "              q_time::date as dayofyear\n",
    "              , extract(dow from q_time) as dayofweek\n",
    "              , extract(hour from q_time) as hourofday\n",
    "              , coalesce(q,0) as q\n",
    "              , coalesce(bv,0) as bv\n",
    "              , 'training' as grouping\n",
    "            from\n",
    "              qualified_counts as qc\n",
    "              left join\n",
    "                bankverified_counts as bvc\n",
    "                on qc.q_time = bvc.bv_time\n",
    "            where\n",
    "              q_time::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "              and q_time::date < '\", date.string, \"'::date\n",
    "\n",
    "            union all\n",
    "\n",
    "\n",
    "            select\n",
    "              q_time::date as dayofyear\n",
    "              , extract(dow from q_time) as dayofweek\n",
    "              , extract(hour from q_time) as hourofday\n",
    "              , coalesce(q,0) as q\n",
    "              , coalesce(bv,0) as bv\n",
    "              , 'test' as grouping\n",
    "            from\n",
    "              qualified_counts as qc\n",
    "              left join\n",
    "                bankverified_counts as bvc\n",
    "                on qc.q_time = bvc.bv_time\n",
    "            where\n",
    "              q_time::date = '\", date.string, \"'::date\n",
    "\n",
    "            order by\n",
    "              dayofyear asc\n",
    "              , hourofday asc\n",
    "            \",\n",
    "            sep = ''\n",
    "            )\n",
    "    }\n",
    "    \n",
    "    return(query.string)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFunnelName = function(atStatus_string) {\n",
    "    \n",
    "    return_string = ''\n",
    "    \n",
    "    if (atStatus_string == 'qualified') {\n",
    "        return_string = 'Q'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt_ibv') {\n",
    "        return_string = 'Attempt_IBV'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified') {\n",
    "        return_string = 'BV'\n",
    "    }\n",
    "    else if (atStatus_string == 'passscorecardratecard') {\n",
    "        return_string = 'SC'\n",
    "    }\n",
    "    else if (atStatus_string == 'contractsigned') {\n",
    "        return_string = 'CS'\n",
    "    }\n",
    "    else if (atStatus_string == 'cs_decisioned') {\n",
    "        return_string = 'CS_Decisioned'\n",
    "    }\n",
    "    else if (atStatus_string == 'funded') {\n",
    "        return_string = 'F'\n",
    "    }\n",
    "    \n",
    "    return(return_string)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFunnelColor = function(atStatus_string) {\n",
    "    \n",
    "    color.decimal = ''\n",
    "    \n",
    "    if (atStatus_string == 'bankverified') {\n",
    "        color.decimal = '#F8766D'\n",
    "    }\n",
    "    else if (atStatus_string == 'passscorecardratecard') {\n",
    "        color.decimal = '#00C0AF'\n",
    "    }\n",
    "    else if (atStatus_string == 'contractsigned') {\n",
    "        color.decimal = '#B983FF'\n",
    "    }\n",
    "    else if (atStatus_string == 'cs_decisioned') {\n",
    "        color.decimal = '#C99800'\n",
    "    }\n",
    "    else if (atStatus_string == 'funded') {\n",
    "        color.decimal = '#619CFF'\n",
    "    }\n",
    "    \n",
    "    return(color.decimal)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getDf = function(date.string, ibv.provider = NA, numerator.string = NA, denominator.string = NA) {\n",
    "    \n",
    "    df = dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        getQueryString(\n",
    "            date.string = date.string,\n",
    "            ibv.provider = ibv.provider\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if (is.na(ibv.provider)) {\n",
    "        \n",
    "        df.subset = df[ , which(colnames(df) %in% c('dayofyear', 'dayofweek', 'hourofday', denominator.string, numerator.string, 'grouping'))]\n",
    "        \n",
    "    } else {\n",
    "        \n",
    "        df.subset = df\n",
    "    }   \n",
    "    \n",
    "    colnames(df.subset) = c('dayofyear', 'dayofweek', 'hourofday', 'denominator', 'numerator', 'grouping')\n",
    "    \n",
    "    \n",
    "    return(df.subset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getDf = function(date.string, ibv.provider = NA) {\n",
    "    \n",
    "#     if (is.na(ibv.provider)) {\n",
    "        \n",
    "#         df = dbGetQuery(\n",
    "#             createReportingConnectionObject(),\n",
    "#             paste(\n",
    "#                 \"\n",
    "#                 with time_limit_gmt as \n",
    "#                 (\n",
    "#                   select\n",
    "#                     date_trunc('hour', min(createddate_)) as createddate_\n",
    "#                   from\n",
    "#                     (\n",
    "#                       select\n",
    "#                         max(createddate) as createddate_\n",
    "#                       from\n",
    "#                         cloudlending.application_status_history\n",
    "\n",
    "#                       union all\n",
    "\n",
    "#                       select\n",
    "#                         max(createddate) as createddate_\n",
    "#                       from\n",
    "#                         cloudlending.applications\n",
    "#                     ) as latest_dates\n",
    "#                 )\n",
    "#                 select\n",
    "#                   (c_ash.createddate at time zone 'America/Chicago')::date as dayofyear\n",
    "#                   , extract(dow from c_ash.createddate at time zone 'America/Chicago') as dayofweek\n",
    "#                   , extract(hour from c_ash.createddate at time zone 'America/Chicago') as hourofday\n",
    "\n",
    "#                 --     , count(distinct case when new_value = 'NEW - ENTERED' then p_ap.loanid end) as newentered\n",
    "#                 --     , count(distinct case when c_ash.old_value = 'NEW - ENTERED' and c_ash.new_value = 'BUSINESS RULES PASSED' then p_ap.loanid end) as bizrulespassed\n",
    "\n",
    "#                   , count(distinct case when left(p_ap.denygrp,1) > '2' \n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as qualified\n",
    "\n",
    "#                   , count(distinct case when (c_ash.old_value = 'BANK VERIFICATION COMPLETED' and c_ash.new_value = 'NEW - SCORECARD GENERATED') or c_ash.new_value = 'BANK VERIFICATION COMPLETED'\n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as bankverified\n",
    "\n",
    "#                   , count(distinct case when c_ash.old_value = 'NEW - PRICING GENERATED' and c_ash.new_value in ('CONTRACT SIGNED', 'WAITING ON STIPULATIONS') \n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as passscorecardratecard\n",
    "\n",
    "#                   , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' \n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as contractsigned\n",
    "\n",
    "#                   , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' and left(p_ap.denygrp,1) not in ('4','5','8') \n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as cs_decisioned\n",
    "\n",
    "#                   , count(distinct case when left(p_ap.denygrp,1) = '9' \n",
    "#                                         then p_ap.loanid \n",
    "#                                         end) as funded\n",
    "\n",
    "#                   , case  when (c_ash.createddate at time zone 'America/Chicago')::date = '\", date.string, \"'::date \n",
    "#                           then 'test' \n",
    "#                           else 'training' \n",
    "#                           end as grouping\n",
    "#                 from\n",
    "#                   public.all_allapps as p_ap\n",
    "#                   inner join\n",
    "#                     cloudlending.applications as c_app\n",
    "#                     on p_ap.loanid = c_app.name\n",
    "#                   inner join\n",
    "#                     cloudlending.application_status_history as c_ash\n",
    "#                     on c_app.id = c_ash.application\n",
    "#                   inner join\n",
    "#                     time_limit_gmt\n",
    "#                     on TRUE\n",
    "#                 where\n",
    "#                   c_app.createddate < createddate_\n",
    "#                   and c_ash.createddate < createddate_\n",
    "#                   and (c_ash.createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "#                   and p_ap.refi = 'N'\n",
    "#                 group by\n",
    "#                   dayofyear\n",
    "#                   , dayofweek\n",
    "#                   , hourofday\n",
    "#                   , grouping\n",
    "#                 order by\n",
    "#                   dayofyear asc\n",
    "#                   , hourofday asc\n",
    "#                 \",\n",
    "#                 sep = ''\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "#     } else {\n",
    "        \n",
    "#         df = dbGetQuery(\n",
    "#             createReportingConnectionObject(),\n",
    "#             paste(\n",
    "#                 \"\n",
    "#                 with time_limit_gmt as \n",
    "#                 (\n",
    "#                   select\n",
    "#                     date_trunc('hour', min(createddate_)) as createddate_\n",
    "#                   from\n",
    "#                     (\n",
    "#                       select\n",
    "#                         max(createddate) as createddate_\n",
    "#                       from\n",
    "#                         cloudlending.application_status_history\n",
    "\n",
    "#                       union all\n",
    "\n",
    "#                       select\n",
    "#                         max(createddate) as createddate_\n",
    "#                       from\n",
    "#                         cloudlending.microbilt_information\n",
    "#                     ) as latest_dates\n",
    "#                 )\n",
    "#                 , qualified as\n",
    "#                 (\n",
    "#                   select\n",
    "#                     application\n",
    "#                     , min(createddate at time zone 'America/Chicago') as createddate_\n",
    "#                   from\n",
    "#                     cloudlending.application_status_history\n",
    "#                     inner join\n",
    "#                       time_limit_gmt\n",
    "#                       on TRUE\n",
    "#                   where\n",
    "#                     createddate < createddate_\n",
    "#                     and old_value = 'BUSINESS RULES PASSED'\n",
    "#                     and new_value = 'BUREAU APPROVED'\n",
    "#                   group by\n",
    "#                     application\n",
    "#                 )\n",
    "#                 , qualified_counts as\n",
    "#                 (\n",
    "#                   select\n",
    "#                     date_trunc('hour', createddate_) as q_time\n",
    "#                     , count(*) as q\n",
    "#                   from\n",
    "#                     qualified\n",
    "#                   group by\n",
    "#                     q_time\n",
    "#                 )\n",
    "#                 , bankverified as\n",
    "#                 (\n",
    "#                   select\n",
    "#                     c_ash.application\n",
    "#                     , min(c_ash.createddate at time zone 'America/Chicago') as createddate_\n",
    "#                   from\n",
    "#                     cloudlending.application_status_history as c_ash\n",
    "#                     inner join\n",
    "#                       time_limit_gmt\n",
    "#                       on TRUE\n",
    "#                     inner join\n",
    "#                       (\n",
    "#                         select\n",
    "#                           application\n",
    "#                         from\n",
    "#                           (\n",
    "#                             select\n",
    "#                               *\n",
    "#                               , row_number() over (partition by application order by createddate desc) as rn\n",
    "#                             from\n",
    "#                               cloudlending.microbilt_information\n",
    "#                             inner join\n",
    "#                               time_limit_gmt\n",
    "#                               on TRUE\n",
    "#                           where\n",
    "#                             createddate < createddate_\n",
    "#                           ) as c_mb\n",
    "#                         where\n",
    "#                           rn = 1\n",
    "#                           and c_mb.ibv_source = '\", ibv.provider, \"'\n",
    "#                       ) as c_mb\n",
    "#                       on c_ash.application = c_mb.application\n",
    "#                   where\n",
    "#                     createddate < createddate_\n",
    "#                     and c_ash.new_value = 'BANK VERIFICATION COMPLETED'\n",
    "#                     or\n",
    "#                       (\n",
    "#                         c_ash.old_value = 'BANK VERIFICATION COMPLETED' \n",
    "#                         and c_ash.new_value = 'NEW - SCORECARD GENERATED'\n",
    "#                       )\n",
    "#                   group by\n",
    "#                     c_ash.application\n",
    "#                 )\n",
    "#                 , bankverified_counts as\n",
    "#                 (\n",
    "#                   select\n",
    "#                     date_trunc('hour', createddate_) as bv_time\n",
    "#                     , count(*) as bv\n",
    "#                   from\n",
    "#                     bankverified\n",
    "#                   group by\n",
    "#                     bv_time\n",
    "#                 )\n",
    "#                 select\n",
    "#                   q_time::date as dayofyear\n",
    "#                   , extract(dow from q_time) as dayofweek\n",
    "#                   , extract(hour from q_time) as hourofday\n",
    "#                   , coalesce(q,0) as q\n",
    "#                   , coalesce(bv,0) as bv\n",
    "#                   , 'training' as grouping\n",
    "#                 from\n",
    "#                   qualified_counts as qc\n",
    "#                   left join\n",
    "#                     bankverified_counts as bvc\n",
    "#                     on qc.q_time = bvc.bv_time\n",
    "#                 where\n",
    "#                   q_time::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "#                   and q_time::date < '\", date.string, \"'::date\n",
    "\n",
    "#                 union all\n",
    "\n",
    "\n",
    "#                 select\n",
    "#                   q_time::date as dayofyear\n",
    "#                   , extract(dow from q_time) as dayofweek\n",
    "#                   , extract(hour from q_time) as hourofday\n",
    "#                   , coalesce(q,0) as q\n",
    "#                   , coalesce(bv,0) as bv\n",
    "#                   , 'test' as grouping\n",
    "#                 from\n",
    "#                   qualified_counts as qc\n",
    "#                   left join\n",
    "#                     bankverified_counts as bvc\n",
    "#                     on qc.q_time = bvc.bv_time\n",
    "#                 where\n",
    "#                   q_time::date = '\", date.string, \"'::date\n",
    "\n",
    "#                 order by\n",
    "#                   dayofyear asc\n",
    "#                   , hourofday asc\n",
    "#                 \",\n",
    "#                 sep = ''\n",
    "#             )\n",
    "#         )\n",
    "#     }\n",
    "    \n",
    "#     return(df)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getDf = function(date.string) {\n",
    "    \n",
    "#     df = dbGetQuery(\n",
    "#         createReportingConnectionObject(),\n",
    "#         paste(\n",
    "#             \"\n",
    "#             with time_limit_gmt as \n",
    "#             (\n",
    "#               select\n",
    "#                 date_trunc('hour', min(createddate_)) as createddate_\n",
    "#               from\n",
    "#                 (\n",
    "#                   select\n",
    "#                     max(createddate) as createddate_\n",
    "#                   from\n",
    "#                     cloudlending.application_status_history\n",
    "\n",
    "#                   union all\n",
    "\n",
    "#                   select\n",
    "#                     max(createddate) as createddate_\n",
    "#                   from\n",
    "#                     cloudlending.applications\n",
    "#                 ) as latest_dates\n",
    "#             )\n",
    "#             select\n",
    "#               (c_ash.createddate at time zone 'America/Chicago')::date as dayofyear\n",
    "#               , extract(dow from c_ash.createddate at time zone 'America/Chicago') as dayofweek\n",
    "#               , extract(hour from c_ash.createddate at time zone 'America/Chicago') as hourofday\n",
    "\n",
    "#             --     , count(distinct case when new_value = 'NEW - ENTERED' then p_ap.loanid end) as newentered\n",
    "#             --     , count(distinct case when c_ash.old_value = 'NEW - ENTERED' and c_ash.new_value = 'BUSINESS RULES PASSED' then p_ap.loanid end) as bizrulespassed\n",
    "\n",
    "#               , count(distinct case when left(p_ap.denygrp,1) > '2' \n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as qualified\n",
    "\n",
    "#               , count(distinct case when (c_ash.old_value = 'BANK VERIFICATION COMPLETED' and c_ash.new_value = 'NEW - SCORECARD GENERATED') or c_ash.new_value = 'BANK VERIFICATION COMPLETED'\n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as bankverified\n",
    "\n",
    "#               , count(distinct case when c_ash.old_value = 'NEW - PRICING GENERATED' and c_ash.new_value in ('CONTRACT SIGNED', 'WAITING ON STIPULATIONS') \n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as passscorecardratecard\n",
    "\n",
    "#               , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' \n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as contractsigned\n",
    "\n",
    "#               , count(distinct case when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' and left(p_ap.denygrp,1) not in ('4','5','8') \n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as cs_decisioned\n",
    "\n",
    "#               , count(distinct case when left(p_ap.denygrp,1) = '9' \n",
    "#                                     then p_ap.loanid \n",
    "#                                     end) as funded\n",
    "\n",
    "#               , case  when (c_ash.createddate at time zone 'America/Chicago')::date = '\", date.string, \"'::date \n",
    "#                       then 'test' \n",
    "#                       else 'training' \n",
    "#                       end as grouping\n",
    "#             from\n",
    "#               public.all_allapps as p_ap\n",
    "#               inner join\n",
    "#                 cloudlending.applications as c_app\n",
    "#                 on p_ap.loanid = c_app.name\n",
    "#               inner join\n",
    "#                 cloudlending.application_status_history as c_ash\n",
    "#                 on c_app.id = c_ash.application\n",
    "#               inner join\n",
    "#                 time_limit_gmt\n",
    "#                 on TRUE\n",
    "#             where\n",
    "#               c_app.createddate < createddate_\n",
    "#               and c_ash.createddate < createddate_\n",
    "#               and (c_ash.createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "#               and p_ap.refi = 'N'\n",
    "#             group by\n",
    "#               dayofyear\n",
    "#               , dayofweek\n",
    "#               , hourofday\n",
    "#               , grouping\n",
    "#             order by\n",
    "#               dayofyear asc\n",
    "#               , hourofday asc\n",
    "#             \",\n",
    "#             sep = ''\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     return(df)\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## 2018-12-18 -- Wells Fargo DL Outage\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0049.csv')\n",
    "\n",
    "# ## 2018-12-20 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_0857.csv')\n",
    "\n",
    "# ## 2010-01-01 -- Complete DL Outage\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_0900.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0007.csv')\n",
    "\n",
    "# ## 2019-01-04 -- Chase DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1130.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0016.csv')\n",
    "\n",
    "\n",
    "# ## 2019-01-05 -- Chase DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1527.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0011.csv')\n",
    "\n",
    "# ## 2019-01-06 -- Chase DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1125.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0012.csv')\n",
    "\n",
    "# ## 2019-01-07 -- Chase DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1103.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0014.csv')\n",
    "\n",
    "\n",
    "# ## 2019-01-08 -- Chase DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1117.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0017.csv')\n",
    "\n",
    "\n",
    "# ## 2019-01-13 -- NFCU DL Errors\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0047.csv')\n",
    "\n",
    "\n",
    "# ## 2019-01-17 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1449.csv')\n",
    "\n",
    "# ## 2019-01-18 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1445.csv')\n",
    "\n",
    "# ## 2019-01-19 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1443.csv')\n",
    "\n",
    "# ## 2019-01-20 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1438.csv')\n",
    "\n",
    "# ## 2019-01-21 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1433.csv')\n",
    "\n",
    "# ## 2019-01-22 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1429.csv')\n",
    "\n",
    "# # 2019-01-23 -- Everything OK\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-26_1428.csv')\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportdlreformat_2019-1-27_0044.csv')\n",
    "\n",
    "# # 2019-01-29 -- Early DL Issues with Chase\n",
    "# # df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportibvproviderreformat_2019-1-30_0837 (1).csv')\n",
    "\n",
    "\n",
    "# # 2019-01-30 -- FUNNEL\n",
    "# df = read.csv('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/data/dataexportfunnelreformat_2019-1-30_1012.csv') \n",
    "\n",
    "\n",
    "\n",
    "# # df$dayofyear = as.Date(df$dayofyear)\n",
    "# # df$grouping = as.character(df$grouping)\n",
    "\n",
    "# # head(df)\n",
    "# # str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Information on the \"Session_Date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output list of DOY, DOW, HOURS.\n",
    "\n",
    "getSessionInfo = function(data) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    current.date = tail(\n",
    "        df$dayofyear,\n",
    "        1\n",
    "    )\n",
    "\n",
    "    current.day = tail(\n",
    "        df$dayofweek,\n",
    "        1\n",
    "    )\n",
    "\n",
    "    current.hours = seq(\n",
    "        from = 0,\n",
    "        to = 23,\n",
    "        by = 1\n",
    "    )\n",
    "\n",
    "    session.info = list(\n",
    "        date = current.date,\n",
    "        dow = current.day,\n",
    "        hours = current.hours\n",
    "    )\n",
    "    \n",
    "    return(session.info)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Aggregated Data for the \"Session_Date\" (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output aggregated (cumulative) data for TEST DATA.\n",
    "\n",
    "getSessionData = function(data, cumulative) {\n",
    "    \n",
    "    ## Create local variable on the parameter:DATA \n",
    "    df = data\n",
    "    df.session = df[which(df$grouping == 'test'), ]\n",
    "\n",
    "    \n",
    "    if (cumulative == TRUE) {\n",
    "        \n",
    "        session.point.estimates = \n",
    "            df.session %>%\n",
    "            group_by(\n",
    "                dayofyear\n",
    "            ) %>%\n",
    "    #         mutate(\n",
    "            transmute(\n",
    "                hourofday = hourofday,\n",
    "                denominator.session = cumsum(denominator),\n",
    "                numerator.session = cumsum(numerator),\n",
    "                ratio.session = ifelse(\n",
    "                    cumsum(denominator) > 0,\n",
    "                    cumsum(numerator)/cumsum(denominator),\n",
    "                    0\n",
    "                )\n",
    "            )\n",
    "    } else if (cumulative == FALSE) {\n",
    "        \n",
    "        session.point.estimates = \n",
    "        df.session %>%\n",
    "        group_by(\n",
    "            dayofyear,\n",
    "            hourofday\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            denominator.session = sum(denominator),\n",
    "            numerator.session = sum(numerator),\n",
    "            ratio.session = ifelse(\n",
    "                sum(denominator) > 0,\n",
    "                sum(numerator)/sum(denominator),\n",
    "                0\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return(session.point.estimates)\n",
    "}\n",
    "\n",
    "# str(getSessionDataCumulative())\n",
    "# getSessionDataCumulative(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Aggregated Data for History (Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output mutated (cumulative) data for TRAINING DATA.\n",
    "## Reliant on getSessionInfo().\n",
    "\n",
    "makeCumulative = function(data) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    df.hist = df[which(df$grouping == 'training'), ]\n",
    "    \n",
    "    df.hist.mutate = \n",
    "        df.hist[which(df.hist$dayofweek == getSessionInfo(data = df)$dow), ] %>%\n",
    "        group_by(\n",
    "            dayofyear\n",
    "        ) %>%\n",
    "        transmute(\n",
    "            dayofweek = dayofweek,\n",
    "            hourofday = hourofday,\n",
    "            denominator = cumsum(denominator),\n",
    "            numerator = cumsum(numerator)\n",
    "        )\n",
    "    \n",
    "    return(df.hist.mutate)\n",
    "    \n",
    "}\n",
    "\n",
    "# makeCumulative(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output aggregated (cumulative) data for TRAINNG DATA.\n",
    "## Reliant on makeCumulative().\n",
    "\n",
    "getHistoricalData = function(data, cumulative) {\n",
    "    \n",
    "    ## Create local variable on the parameter:DATA     \n",
    "    df = data\n",
    "    \n",
    "    \n",
    "    if (cumulative == TRUE) {\n",
    "    \n",
    "        df.hist.mutate = makeCumulative(data = df)\n",
    "\n",
    "        historical.point.estimates = \n",
    "            df.hist.mutate %>%\n",
    "            group_by(\n",
    "                hourofday\n",
    "            ) %>%\n",
    "            summarize(\n",
    "                denominator.hist = sum(denominator),\n",
    "                numerator.hist = sum(numerator),\n",
    "                r.hist = sum(numerator)/sum(denominator),\n",
    "                n.hist = sum(denominator),\n",
    "                sd.denominator.hist = sd(denominator),\n",
    "                sd.numerator.hist = sd(numerator),\n",
    "                mu.denominator.hist = mean(denominator),\n",
    "                corr.hist = cor(denominator, numerator),\n",
    "                se.hist = sqrt(\n",
    "                    (\n",
    "                        (\n",
    "                            sd(numerator)^2 + \n",
    "                            sd(denominator)^2 * (sum(numerator)/sum(denominator))^2 -\n",
    "                            2 * sum(numerator)/sum(denominator) * cor(denominator, numerator) * sd(numerator) * sd(denominator)\n",
    "                        ) /\n",
    "                        (\n",
    "                            sum(denominator) *\n",
    "                            mean(denominator)^2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    } else if (cumulative == FALSE) {\n",
    "\n",
    "        df.hist = df[which(df$grouping == 'training'), ]\n",
    "\n",
    "        historical.point.estimates = \n",
    "            df.hist[which(df.hist$dayofweek == getSessionInfo(data = df)$dow), ] %>%\n",
    "            group_by(\n",
    "                hourofday\n",
    "            ) %>%\n",
    "            summarize(\n",
    "                denominator.hist = sum(denominator),\n",
    "                numerator.hist = sum(numerator),\n",
    "                r.hist = sum(numerator)/sum(denominator),\n",
    "                n.hist = sum(denominator),\n",
    "                sd.denominator.hist = sd(denominator),\n",
    "                sd.numerator.hist = sd(numerator),\n",
    "                mu.denominator.hist = mean(denominator),\n",
    "                corr.hist = cor(denominator, numerator),\n",
    "                se.hist = sqrt(\n",
    "                    (\n",
    "                        (\n",
    "                            sd(numerator)^2 + \n",
    "                            sd(denominator)^2 * (sum(numerator)/sum(denominator))^2 -\n",
    "                            2 * sum(numerator)/sum(denominator) * cor(denominator, numerator) * sd(numerator) * sd(denominator)\n",
    "                        ) /\n",
    "                        (\n",
    "                            sum(denominator) *\n",
    "                            mean(denominator)^2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    }\n",
    "\n",
    "    return(historical.point.estimates)\n",
    "}\n",
    "\n",
    "\n",
    "# str(getHistoricalDataCumulative(data = df))\n",
    "# rbind(head(getHistoricalData(),3), tail(getHistoricalData(),3))\n",
    "# getHistoricalDataCumulative(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data Frame to store final information for ggplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output Initialized CI data frame.\n",
    "## Reliant on getSessionDataCumulative() and getHistoricalDataCumulative().\n",
    "\n",
    "getInitialCI = function(data, cumulative) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    df.session = getSessionData(data = df, cumulative = cumulative)\n",
    "    df.historical = getHistoricalData(data = df, cumulative = cumulative)\n",
    "\n",
    "    ci.information = data.frame(\n",
    "\n",
    "        date.session = rep(max(as.Date(df.session$dayofyear)),24),\n",
    "        hour.session = df.historical$hourofday,\n",
    "        r.session = c(df.session$ratio.session, rep(0, 24 - length(df.session$ratio.session))),\n",
    "        r.hist = df.historical$r.hist,\n",
    "        se.hist = df.historical$se.hist,\n",
    "        z.lower = rep(0,24),\n",
    "        z.upper = rep(0,24),\n",
    "        ci.lower = rep(0,24),\n",
    "        ci.upper = rep(0,24)\n",
    "    )\n",
    "    \n",
    "    return(ci.information)\n",
    "}\n",
    "\n",
    "# getInitialCI(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame and Bootstrap parameters.\n",
    "## Output Finalized CI data frame.\n",
    "## Reliant on getInitialCI() and makeCumulative().\n",
    "\n",
    "getBootstrapInterval = function(data, cumulative, B, alpha) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "#     ## Set Start Time.\n",
    "#     start_time = Sys.time()\n",
    "    \n",
    "    ## Initialize final output data frame.\n",
    "    ci.information = getInitialCI(data = df, cumulative = cumulative)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Initialize data for bootstrap.\n",
    "    if (cumulative == TRUE) {\n",
    "        \n",
    "        df.training.dow = makeCumulative(data = df)\n",
    "    } else if (cumulative == FALSE) {\n",
    "        \n",
    "        df.training = df[which(df$grouping == 'training'), ]\n",
    "        df.training.dow = df.training[which(df.training$dayofweek == getSessionInfo(data = df)$dow), ]\n",
    "    }\n",
    "    \n",
    "        \n",
    "    \n",
    "    ## Initialize container for bootstrap.\n",
    "    bootstrap_z = vector(length = B)\n",
    "    \n",
    "    \n",
    "    for (i in 1:24) {\n",
    "\n",
    "        for (j in 1:B) {\n",
    "\n",
    "\n",
    "\n",
    "            ## Subset the data to the current HOD (i).\n",
    "            df.training.dow.hour = df.training.dow[which(df.training.dow$hourofday == i - 1), ]\n",
    "\n",
    "            index = seq(\n",
    "                1, \n",
    "                nrow(df.training.dow.hour)\n",
    "            )\n",
    "            resample_index = sample(\n",
    "                x = index, \n",
    "                size = length(index), \n",
    "                replace = TRUE\n",
    "            )\n",
    "            df.training.dow.hour.resample = df.training.dow.hour[resample_index, ]\n",
    "\n",
    "\n",
    "            ## Calculate statistics from the resample.\n",
    "            r = sum(df.training.dow.hour.resample$numerator)/sum(df.training.dow.hour.resample$denominator)\n",
    "            n = sum(df.training.dow.hour.resample$denominator)\n",
    "            sx = sd(df.training.dow.hour.resample$denominator)\n",
    "            sy = sd(df.training.dow.hour.resample$numerator)\n",
    "            mx = mean(df.training.dow.hour.resample$denominator)\n",
    "            corr = cor(df.training.dow.hour.resample$numerator, df.training.dow.hour.resample$denominator)\n",
    "\n",
    "            se = sqrt(\n",
    "                (r^2*sx^2 + sy^2 - 2*r*corr*sx*sy)/\n",
    "                (n*mx^2)\n",
    "            )\n",
    "\n",
    "\n",
    "            ## Calculate statistics from the training data.\n",
    "            mu = ci.information$r.hist[i]\n",
    "\n",
    "\n",
    "            ## Calculate the bootstrap Z\n",
    "            bootstrap_z[j] = (r - mu)/se\n",
    "        }\n",
    "\n",
    "\n",
    "        ## For each hour, take Percentiles of the Bootstrap Z vector to caluclate the confidence interval for that hour.\n",
    "        bootstrap_z = sort(bootstrap_z)\n",
    "\n",
    "        ci.information$z.lower[i] = bootstrap_z[alpha/2*B]\n",
    "        ci.information$z.upper[i] = bootstrap_z[(1-alpha/2)*B]\n",
    "\n",
    "        ci.information$ci.lower = ci.information$r.hist - ci.information$z.upper * ci.information$se.hist\n",
    "        ci.information$ci.upper = ci.information$r.hist - ci.information$z.lower * ci.information$se.hist\n",
    "    }\n",
    "    \n",
    "    return(ci.information)\n",
    "    \n",
    "#     elapsed_time = Sys.time() - start_time\n",
    "    \n",
    "#     return(\n",
    "#         list(\n",
    "#             ci.information = ci.information, \n",
    "#             elapsed_time = elapsed_time\n",
    "#         )\n",
    "#     )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth the CI.Lower Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smoothLowerBound = function(ci.information, iterations) {\n",
    "    \n",
    "    ci.information.smooth = ci.information\n",
    "    \n",
    "    for (i in 1:iterations) {\n",
    "    \n",
    "        for (j in (0+1):(23-1)) {\n",
    "\n",
    "            ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)] = mean(\n",
    "                c(ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)-1], ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)+1])\n",
    "            )\n",
    "        }        \n",
    "    }\n",
    "    \n",
    "    return(ci.information.smooth)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getBootstrapPlot = function(df.bi, ibv.provider = NA, numerator.string = NA, denominator.string = NA, alpha, cumulative) {\n",
    "    \n",
    "    df = df.bi\n",
    "    \n",
    "    plot.alpha = paste(round(alpha*100,0), '%', sep = '')\n",
    "    plot.cumulative = ifelse(\n",
    "        cumulative == TRUE,\n",
    "        '(Cumulative)',\n",
    "        '(Not Cumulative)'\n",
    "    )\n",
    "    \n",
    "    if (is.na(ibv.provider)) {\n",
    "        \n",
    "        plot.funnel = ifelse(\n",
    "            paste(getFunnelName(numerator.string),'/',getFunnelName(denominator.string), sep = '') == 'F/Q',\n",
    "            'Funding Rate',\n",
    "            paste(getFunnelName(numerator.string),'/',getFunnelName(denominator.string), sep = '')\n",
    "        )\n",
    "        plot.color = ifelse(\n",
    "            plot.funnel == 'Funding Rate',\n",
    "            '#FD61D1',\n",
    "            getFunnelColor(numerator.string)\n",
    "        )\n",
    "        \n",
    "    } else {\n",
    "        \n",
    "        plot.funnel = paste(ibv.provider,' Successes/Q', sep = '')\n",
    "        plot.color = ifelse(\n",
    "            ibv.provider == 'DecisionLogic',\n",
    "            '#00B0F6',\n",
    "            '#E58700'\n",
    "        )\n",
    "            \n",
    "    }\n",
    "    \n",
    "            \n",
    "    \n",
    "    ggplot(\n",
    "        data = df,\n",
    "        mapping = aes(\n",
    "            x = hour.session, \n",
    "            y = r.session\n",
    "        )        \n",
    "    ) +\n",
    "    geom_col(\n",
    "        fill = plot.color,\n",
    "        color = 'black'\n",
    "    ) + \n",
    "    labs(\n",
    "        x =\"Time of Day\", \n",
    "        y = \"Success/Q\", \n",
    "        title = paste(\n",
    "            df$date.session,\n",
    "            \"\\n\", \"Bars: Non-Cohorted\", plot.funnel, plot.cumulative, \n",
    "            \"\\n\", \"Line:\", plot.alpha,\"lower bound confidence interval of bars\"\n",
    "        )\n",
    "    ) + \n",
    "    geom_line(\n",
    "        aes(\n",
    "            x = hour.session, \n",
    "            y = ci.lower\n",
    "        ), \n",
    "        color = 'black', \n",
    "        size=1.5\n",
    "    ) + \n",
    "#     geom_line(\n",
    "#         aes(\n",
    "#             x = hour.session, \n",
    "#             y = ci.upper\n",
    "#         ), \n",
    "#         color = 'gray', \n",
    "#         size=1\n",
    "#     ) + \n",
    "    scale_y_continuous(\n",
    "        labels = scales::percent \n",
    "    ) + \n",
    "    scale_x_continuous(\n",
    "        breaks = seq(0,23,4)\n",
    "    )    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make all the above into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFinalPlot = function(\n",
    "    date.string, \n",
    "    ibv.provider = NA, \n",
    "    numerator.string = NA, \n",
    "    denominator.string = NA,\n",
    "    cumulative,\n",
    "    B,\n",
    "    alpha,\n",
    "    smooth.iterations\n",
    ") {\n",
    "    \n",
    "    start = Sys.time()\n",
    "\n",
    "    plot = getBootstrapPlot(\n",
    "        df.bi = smoothLowerBound(\n",
    "            ci.information = getBootstrapInterval(\n",
    "                data = getDf(\n",
    "                    date.string = date.string, \n",
    "                    ibv.provider = ibv.provider,\n",
    "                    numerator.string = numerator.string,\n",
    "                    denominator.string = denominator.string\n",
    "                ),\n",
    "                cumulative = cumulative,\n",
    "                B = B,\n",
    "                alpha = alpha\n",
    "            ),\n",
    "            iterations = smooth.iterations\n",
    "        ),\n",
    "        ibv.provider = ibv.provider,\n",
    "        numerator.string = numerator.string,\n",
    "        denominator.string = denominator.string,\n",
    "        alpha = alpha,\n",
    "        cumulative = cumulative\n",
    "    )\n",
    "\n",
    "    end = Sys.time()\n",
    "    run.time = end - start\n",
    "    \n",
    "    output.list = list(\n",
    "        run.time,\n",
    "        plot\n",
    "    )\n",
    "    \n",
    "#     return(output.list)\n",
    "    return(plot)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllFinalPlots = function(date.string, B, alpha, smooth.iterations) {\n",
    "    \n",
    "    start = Sys.time()\n",
    "    \n",
    "    plot.list = list(\n",
    "        plot.1 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            ibv.provider = 'DecisionLogic',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),    \n",
    "        plot.2 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            ibv.provider = 'DecisionLogic',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),    \n",
    "\n",
    "        plot.3 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            ibv.provider = 'MicroBilt',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),    \n",
    "        plot.4 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            ibv.provider = 'MicroBilt',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.5 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'bankverified',\n",
    "            denominator.string = 'qualified',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.6 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'bankverified',\n",
    "            denominator.string = 'qualified',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.7 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'passscorecardratecard',\n",
    "            denominator.string = 'bankverified',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.8 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'passscorecardratecard',\n",
    "            denominator.string = 'bankverified',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.9 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'contractsigned',\n",
    "            denominator.string = 'passscorecardratecard',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.10 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'contractsigned',\n",
    "            denominator.string = 'passscorecardratecard',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.11 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'cs_decisioned',\n",
    "            denominator.string = 'contractsigned',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.12 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'cs_decisioned',\n",
    "            denominator.string = 'contractsigned',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.13 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'cs_decisioned',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.14 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'cs_decisioned',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "\n",
    "        plot.15 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'qualified',\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        ),\n",
    "        plot.16 = getFinalPlot(\n",
    "            date.string = date.string,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'qualified',\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha,\n",
    "            smooth.iterations = 2\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    end = Sys.time()\n",
    "    run.time = start - end\n",
    "    \n",
    "    output.list = list(\n",
    "        run.time,\n",
    "        plot.list\n",
    "    )\n",
    "    \n",
    "    return(output.list)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllFinalPlots(date.string = '2019-01-30', B = 100, alpha = 0.03, smooth.iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.bi = getBootstrapInterval(\n",
    "    data = df,\n",
    "    B = 5000,\n",
    "    alpha = 0.03\n",
    ")$ci.information\n",
    "\n",
    "ggplot() +\n",
    "geom_line(\n",
    "    data = df.bi,\n",
    "    mapping = aes(\n",
    "        x = hour.session,\n",
    "        y = r.session\n",
    "    ),\n",
    "    color = 'skyblue',\n",
    "    size = 3\n",
    ") +\n",
    "geom_line(\n",
    "    data = df.bi,\n",
    "    mapping = aes(\n",
    "        x = hour.session,\n",
    "        y = ci.lower\n",
    "    ),\n",
    "    color = 'red',\n",
    "    size = 1,\n",
    "    linetype = 6\n",
    ") +\n",
    "geom_point(\n",
    "    data = makeCumulative(data = df),\n",
    "    mapping = aes(\n",
    "        x = hourofday,\n",
    "        y = dl.hist.cum/q.hist.cum\n",
    "    ),\n",
    "    color = 'black',\n",
    "    size = 0.8,\n",
    "    alpha = 0.1\n",
    ") +\n",
    "# geom_ribbon(\n",
    "#     data = makeCumulative(data = df) %>%\n",
    "#         group_by(\n",
    "#             hourofday\n",
    "#         ) %>%\n",
    "#         summarize(\n",
    "#             ribbon.lower = min(dl.hist.cum/q.hist.cum),\n",
    "#             ribbon.upper = max(dl.hist.cum/q.hist.cum)\n",
    "#         ), \n",
    "#     mapping = aes(\n",
    "#         x = hourofday,\n",
    "#         ymin = ribbon.lower,\n",
    "#         ymax = ribbon.upper\n",
    "#     ),\n",
    "#     color = 'black',\n",
    "#     size = 0.8,\n",
    "#     alpha = 0.1\n",
    "# ) +\n",
    "scale_y_continuous(\n",
    "    labels = scales::percent,\n",
    "#     limits = c(\n",
    "#         min(dl.hist.cum/q.hist.cum),\n",
    "#         max(dl.hist.cum/q.hist.cum),\n",
    "#     ) \n",
    "    limits = c(0.20,0.70)\n",
    ") \n",
    "\n",
    "\n",
    "# + \n",
    "# labs(\n",
    "#     x =\"Time of Day\", \n",
    "#     y = \"Success/Q\", \n",
    "#     title = paste(\n",
    "#         \"DL \", getSessionInfo(data = df)$date,\n",
    "#         \"\\n\", \"Bars: Non-Cohorted DL Success/Q (Cumulative)\", \n",
    "#         \"\\n\", \"Line: 5% lower bound confidence interval of bars\")\n",
    "# ) + \n",
    "# geom_line(\n",
    "#     aes(\n",
    "#         x = hour.session, \n",
    "#         y = ci.lower\n",
    "#     ), \n",
    "#     color = 'red', \n",
    "#     size=1\n",
    "# ) + \n",
    "# # geom_line(\n",
    "# #     aes(\n",
    "# #         x = hour.session, \n",
    "# #         y = ci.upper\n",
    "# #     ), \n",
    "# #     color = 'blue', \n",
    "# #     size=1\n",
    "# # ) + \n",
    "# scale_x_continuous(\n",
    "#     breaks = seq(0,23,4)\n",
    "# )# + geom_line(aes(x=hourofday, y=upper), color='springgreen4', size=1) + scale_y_continuous(labels=scales::percent) + scale_x_continuous(breaks=seq(0,23,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
