{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Prevent scientific notation.\n",
    "options(scipen = 999)\n",
    "\n",
    "##Turn Warnings off.\n",
    "options(warn = -1)\n",
    "\n",
    "##Set repo\n",
    "options(repos=structure(c(CRAN='https://ftp.ussg.iu.edu/CRAN/')))\n",
    "\n",
    "##Set Java Environment Variable\n",
    "# Sys.setenv(JAVA_HOME = 'C:\\\\Program Files (x86)\\\\Java\\\\jre1.8.0_202')\n",
    "if (Sys.getenv('JAVA_HOME') != '') {\n",
    "    Sys.setenv(JAVA_HOME = '')\n",
    "}\n",
    "\n",
    "## Warnings back on.\n",
    "# options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find.java <- function() {\n",
    "#         for (root in c(\"HLM\", \"HCU\")) for (key in c(\"Software\\\\JavaSoft\\\\Java Runtime Environment\", \n",
    "#             \"Software\\\\JavaSoft\\\\Java Development Kit\")) {\n",
    "#             hive <- try(utils::readRegistry(key, root, 2), \n",
    "#               silent = TRUE)\n",
    "#             if (!inherits(hive, \"try-error\")) \n",
    "#               return(hive)\n",
    "#         }\n",
    "#         hive\n",
    "#     }\n",
    "\n",
    "# find.java()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check.packages = function(pkg) {\n",
    "    new.pkg = pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n",
    "    if (length(new.pkg)) \n",
    "        install.packages(new.pkg, dependencies = TRUE)\n",
    "    sapply(pkg, require, character.only = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RPostgreSQL</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>RJDBC</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggplot2</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>dplyr</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>gridExtra</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>cowplot</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggplotify</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>rJava</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggpubr</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>lubridate</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>mailR</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>zoo</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>glue</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RPostgreSQL] TRUE\n",
       "\\item[RJDBC] TRUE\n",
       "\\item[ggplot2] TRUE\n",
       "\\item[dplyr] TRUE\n",
       "\\item[gridExtra] TRUE\n",
       "\\item[cowplot] TRUE\n",
       "\\item[ggplotify] TRUE\n",
       "\\item[rJava] TRUE\n",
       "\\item[ggpubr] TRUE\n",
       "\\item[lubridate] TRUE\n",
       "\\item[mailR] TRUE\n",
       "\\item[zoo] TRUE\n",
       "\\item[glue] TRUE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RPostgreSQL\n",
       ":   TRUERJDBC\n",
       ":   TRUEggplot2\n",
       ":   TRUEdplyr\n",
       ":   TRUEgridExtra\n",
       ":   TRUEcowplot\n",
       ":   TRUEggplotify\n",
       ":   TRUErJava\n",
       ":   TRUEggpubr\n",
       ":   TRUElubridate\n",
       ":   TRUEmailR\n",
       ":   TRUEzoo\n",
       ":   TRUEglue\n",
       ":   TRUE\n",
       "\n"
      ],
      "text/plain": [
       "RPostgreSQL       RJDBC     ggplot2       dplyr   gridExtra     cowplot \n",
       "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
       "  ggplotify       rJava      ggpubr   lubridate       mailR         zoo \n",
       "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
       "       glue \n",
       "       TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check.packages(c('RPostgreSQL', 'RJDBC', 'ggplot2', 'dplyr', 'gridExtra', 'cowplot', 'ggplotify', 'rJava', 'ggpubr', 'lubridate', 'mailR', 'zoo', 'glue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "killDbConnections = function () {\n",
    "  all_cons = dbListConnections(PostgreSQL())\n",
    "  print(all_cons)\n",
    "  for(con in all_cons)\n",
    "    +  dbDisconnect(con)\n",
    "  \n",
    "#   print(paste(length(all_cons), \" connections killed.\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkConnections = function() {\n",
    "    \n",
    "    print(paste(length(dbListConnections(PostgreSQL())), \" connections active.\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "createReportingConnectionObject = function() {\n",
    "    \n",
    "    killDbConnections()\n",
    "    \n",
    "    drv = dbDriver('PostgreSQL')\n",
    "\n",
    "    reporting = dbConnect(\n",
    "      drv,\n",
    "      dbname = 'reporting',\n",
    "      host = 'reporting.ckpglb17yttu.us-east-1.rds.amazonaws.com',\n",
    "      port = 5432,\n",
    "      user = 'jchang',\n",
    "      password = 'QvxqgasA3M2hQw5D'\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "createHeapConnectionObject = function() {\n",
    "    \n",
    "    killDbConnections()\n",
    "    \n",
    "    drv = dbDriver('PostgreSQL')\n",
    "\n",
    "    reporting = dbConnect(\n",
    "      drv,\n",
    "      dbname = 'oppreddb',\n",
    "      host = 'oppred.cyt7r7wgkc6b.us-east-1.redshift.amazonaws.com',\n",
    "      port = 5439,\n",
    "      user = 'jchang',\n",
    "      password = 'az6fE818ERlyjoCH'\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting -- Funnel Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## This returns counts of each status occurrence, grouped by DOY, DOW, and HOD.\n",
    "##### with time_limit_gmt <- 0.35s\n",
    "#### time zone America/Chicago doubled\n",
    "\n",
    "getFunnel = function(date.string) {\n",
    "    \n",
    "    df = dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            with time_limit_gmt as \n",
    "            (\n",
    "                select\n",
    "                    date_trunc('hour', min(createddate_)) as createddate_\n",
    "                from\n",
    "                    (\n",
    "                        select\n",
    "                            max(createddate) as createddate_\n",
    "                        from\n",
    "                            cloudlending.application_status_history\n",
    "                        union all\n",
    "                        select\n",
    "                            max(createddate) as createddate_\n",
    "                        from\n",
    "                            cloudlending.applications\n",
    "                        union all\n",
    "                        select\n",
    "                            max(createddate) as createddate_\n",
    "                        from\n",
    "                            cloudlending.microbilt_information\n",
    "                    ) as latest_dates\n",
    "            )\n",
    "            , c_app as\n",
    "            (\n",
    "                select\n",
    "                    id\n",
    "                    , createddate\n",
    "                    , denialreason\n",
    "                from\n",
    "                    cloudlending.applications\n",
    "                where\n",
    "                    type_formula = 'New'\n",
    "                    and createddate >= now()::date - '4 months'::interval\n",
    "            )\n",
    "            , c_ash as\n",
    "            (\n",
    "                select\n",
    "                    application\n",
    "                    , createddate\n",
    "                    , old_value\n",
    "                    , new_value\n",
    "                from\n",
    "                    cloudlending.application_status_history\n",
    "                where\n",
    "                    createddate >= now()::date - '4 months'::interval\n",
    "            )\n",
    "            select\n",
    "                (c_ash.createddate at time zone 'America/Chicago')::date as dayofyear\n",
    "                , extract(dow from c_ash.createddate at time zone 'America/Chicago') as dayofweek\n",
    "                , extract(hour from c_ash.createddate at time zone 'America/Chicago') as hourofday\n",
    "                , count(distinct case \twhen old_value = 'BUSINESS RULES PASSED' and new_value = 'BUREAU APPROVED' then c_app.id end) as qualified\n",
    "                , count(distinct case \twhen new_value = 'BANK VERIFICATION COMPLETED' or (old_value in ('AUTO BANK VERIFICATION FAILED', 'REVIEW REQUIRED - BANK VERIFICATION') and new_value = 'NEW - SCORECARD GENERATED') then c_app.id end) as bankverified\n",
    "                , count(distinct case \twhen old_value = 'NEW - PRICING GENERATED' and new_value in ('CONTRACT SIGNED', 'WAITING ON STIPULATIONS') then c_app.id end) as passscorecardratecard\n",
    "                , count(distinct case \twhen old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and new_value = 'CONTRACT SIGNED' then c_app.id end) as contractsigned\n",
    "                , count(distinct case \twhen (c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS') and c_ash.new_value = 'CONTRACT SIGNED' and c_app.denialreason in ('Agent', 'Denied - Bankruptcy', 'Denied - First Payment Date', 'Verify'))\n",
    "                                        or (c_ash.new_value = 'LOAN APPROVED' and c_ash.old_value != c_ash.new_value)\n",
    "                                        then c_app.id end) as cs_decisioned\n",
    "                , count(distinct case \twhen new_value = 'LOAN APPROVED' and old_value != new_value then c_app.id end) as funded\n",
    "                , case \twhen (c_ash.createddate at time zone 'America/Chicago')::date = '\", date.string, \"'::date\n",
    "                        then 'test'\t\n",
    "                        else 'training'\n",
    "                        end as grouping\n",
    "                , count(distinct case \twhen extract(epoch from c_ash.createddate - c_mb.createddate) <= 30 and c_ash.new_value = 'BANK VERIFICATION COMPLETED' and ibv_source = 'DecisionLogic' then c_app.id end) as \", '\"bankverified.dl\"', \"\n",
    "                , count(distinct case \twhen extract(epoch from c_ash.createddate - c_mb.createddate) <= 30 and c_ash.new_value = 'BANK VERIFICATION COMPLETED' and ibv_source = 'MicroBilt' then c_app.id end) as \", '\"bankverified.mb\"', \" \n",
    "            from\n",
    "                c_app\n",
    "                inner join\n",
    "                    c_ash\n",
    "                    on c_app.id = c_ash.application\n",
    "                left join\n",
    "                    cloudlending.microbilt_information as c_mb\n",
    "                    on c_ash.application = c_mb.application\n",
    "                inner join\n",
    "                    time_limit_gmt\n",
    "                    on TRUE\n",
    "            where\n",
    "                c_app.createddate < createddate_\n",
    "                and c_ash.createddate < createddate_\n",
    "                and (c_ash.createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "                and (c_ash.createddate at time zone 'America/Chicago')::date <= '\", date.string, \"'::date\n",
    "            group by\n",
    "                dayofyear\n",
    "                , dayofweek\n",
    "                , hourofday\n",
    "                , grouping\n",
    "            order by\n",
    "                dayofyear asc\n",
    "                , hourofday asc\n",
    "            \",\n",
    "            sep = ''\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting -- Last Refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns the latest full refresh of the data used. To be put into caption of plots.\n",
    "\n",
    "getLatestReportingRefresh = function() {\n",
    "    \n",
    "    dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                date_trunc('hour', min(createddate_)) as createddate_\n",
    "            from\n",
    "                (\n",
    "                select\n",
    "                    max(createddate at time zone 'America/Chicago') as createddate_\n",
    "                from\n",
    "                    cloudlending.application_status_history\n",
    "                union all\n",
    "                select\n",
    "                    max(createddate at time zone 'America/Chicago') as createddate_\n",
    "                from\n",
    "                    cloudlending.applications\n",
    "                union all\n",
    "                select\n",
    "                    max(createddate at time zone 'America/Chicago') as createddate_\n",
    "                from\n",
    "                    cloudlending.microbilt_information\n",
    "                ) as latest_dates\n",
    "            \",\n",
    "            sep = ''\n",
    "        )\n",
    "    )$createddate_\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heap -- IBV Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns a data frame of all the apps that attempt DL.\n",
    "\n",
    "getAttemptDLRaw = function(date.string) {\n",
    "    \n",
    "    df.heap = dbGetQuery(\n",
    "        createHeapConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                h_users.\", '\"', 'identity', '\"', \" as contact\n",
    "                , h_dl.time at time zone 'GMT' at time zone 'America/Chicago' as time_\n",
    "                , 'DecisionLogic' as ibv_source\n",
    "                , case  when (h_dl.time at time zone 'GMT' at time zone 'America/Chicago')::date = '\", date.string, \"'::date\n",
    "                        then 'test'\n",
    "                        else 'training'\n",
    "                        end as grouping\n",
    "            from\n",
    "                main_production._completed_decisionlogic_iframe_ as h_dl\n",
    "                inner join\n",
    "                    main_production.users as h_users\n",
    "                    on h_dl.user_id = h_users.user_id\n",
    "            where\n",
    "                (h_dl.time at time zone 'GMT' at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "                and (h_dl.time at time zone 'GMT' at time zone 'America/Chicago')::date <= '\", date.string, \"'::date\n",
    "            \",\n",
    "            sep = ''\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df.reporting = dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                name\n",
    "                , createddate at time zone 'America/Chicago' as createddate_\n",
    "                , contact\n",
    "            from\n",
    "                cloudlending.applications\n",
    "            where \n",
    "              type_formula = 'New'\n",
    "              and (createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "              and (createddate at time zone 'America/Chicago')::date <= '\", date.string, \"'::date\n",
    "            \"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "    df.merged = merge(\n",
    "        x = df.heap,\n",
    "        y = df.reporting,\n",
    "        by.x = 'contact',\n",
    "        by.y = 'contact'\n",
    "    )\n",
    "    \n",
    "    df.boxed = df.merged[\n",
    "        which(\n",
    "            df.merged$time_ >= df.merged$createddate_ & \n",
    "            as.Date(df.merged$time_) <= as.Date(df.merged$createddate_) + 15\n",
    "        ), ]\n",
    "    \n",
    "    df.unique = df.boxed %>%\n",
    "        group_by(\n",
    "            name,\n",
    "            grouping\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            time_ = min(time_)\n",
    "        )\n",
    "\n",
    "    return(df.unique)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns a data frame of all the apps that attempt MB.\n",
    "\n",
    "getAttemptMBRaw = function(date.string) {\n",
    "    \n",
    "    df.heap = dbGetQuery(\n",
    "        createHeapConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                h_users.\", '\"', 'identity', '\"', \" as contact\n",
    "                , h_mb.time at time zone 'GMT' at time zone 'America/Chicago' as time_\n",
    "                , 'MicroBilt' as ibv_source\n",
    "                , case  when (h_mb.time at time zone 'GMT' at time zone 'America/Chicago')::date = '\", date.string, \"'::date\n",
    "                        then 'test'\n",
    "                        else 'training'\n",
    "                        end as grouping\n",
    "            from\n",
    "                main_production._completed_microbilt_iframe_ as h_mb\n",
    "                inner join\n",
    "                    main_production.users as h_users\n",
    "                    on h_mb.user_id = h_users.user_id\n",
    "            where\n",
    "              (h_mb.time at time zone 'GMT' at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "              and (h_mb.time at time zone 'GMT' at time zone 'America/Chicago')::date <= '\", date.string, \"'::date\n",
    "            \",\n",
    "            sep = ''\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df.reporting = dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                name\n",
    "                , createddate at time zone 'America/Chicago' as createddate_\n",
    "                , contact\n",
    "            from\n",
    "                cloudlending.applications\n",
    "            where \n",
    "              type_formula = 'New'\n",
    "              and (createddate at time zone 'America/Chicago')::date >= '\", date.string, \"'::date - '3 months'::interval\n",
    "              and (createddate at time zone 'America/Chicago')::date <= '\", date.string, \"'::date\n",
    "            \"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "    df.merged = merge(\n",
    "        x = df.heap,\n",
    "        y = df.reporting,\n",
    "        by.x = 'contact',\n",
    "        by.y = 'contact'\n",
    "    )\n",
    "    \n",
    "    df.boxed = df.merged[\n",
    "        which(\n",
    "            df.merged$time_ >= df.merged$createddate_ & \n",
    "            as.Date(df.merged$time_) <= as.Date(df.merged$createddate_) + 15\n",
    "        ), ]\n",
    "    \n",
    "    df.unique = df.boxed %>%\n",
    "        group_by(\n",
    "            name,\n",
    "            grouping\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            time_ = min(time_)\n",
    "        )\n",
    "\n",
    "    \n",
    "    return(df.unique)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This unions the above raw DL and MB attempts, and only retains the first IBV attempt.\n",
    "## This is done outside of the query due to troubles connecting to JDBC AWS - can't use subqueries in current connection.\n",
    "\n",
    "getAttemptBothRaw = function (dl.data.raw, mb.data.raw) {\n",
    "    \n",
    "    data.both = rbind(\n",
    "        dl.data.raw, \n",
    "        mb.data.raw\n",
    "    )\n",
    "    \n",
    "    df.unique = data.both %>%\n",
    "        group_by(\n",
    "            name,\n",
    "            grouping\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            time_ = min(time_)\n",
    "        )\n",
    "    \n",
    "    return(df.unique)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This groups either DL, MB, or All attempts (if NA) into DOY, DOW, HOD.\n",
    "\n",
    "getAttemptAggregate = function(data, ibv.provider = NA) {\n",
    "    \n",
    "    df.unique = data\n",
    "    \n",
    "    df.aggregated = df.unique %>%\n",
    "        group_by(\n",
    "            dayofyear = date(time_),\n",
    "            dayofweek = ifelse(\n",
    "                wday(time_, week_start = getOption(\"lubridate.week.start\", 1)) == 7,\n",
    "                0,\n",
    "                wday(time_, week_start = getOption(\"lubridate.week.start\", 1))),\n",
    "            hourofday = hour(time_),\n",
    "            grouping\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            attempt.ibv = n_distinct(name)\n",
    "        )\n",
    "\n",
    "    if (!is.na(ibv.provider)) {\n",
    "        colnames(df.aggregated)[which(colnames(df.aggregated) == 'attempt.ibv')] = ifelse(\n",
    "            ibv.provider == 'DecisionLogic',\n",
    "            'attempt.dl',\n",
    "            'attempt.mb'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return(df.aggregated)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heap -- Last Refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns the lastest full refresh of the data used. Used for limiting the time and caption in the ggplots below.\n",
    "\n",
    "getLatestHeapRefresh = function() {\n",
    "    \n",
    "    dbGetQuery(\n",
    "        createHeapConnectionObject(),\n",
    "        paste(\n",
    "            \"\n",
    "            select\n",
    "                date_trunc('hour', min(time_)) as time_\n",
    "            from\n",
    "                (\n",
    "                select\n",
    "                    max(time at time zone 'GMT' at time zone 'America/Chicago') as time_\n",
    "                from\n",
    "                    main_production._completed_decisionlogic_iframe_\n",
    "                union all\n",
    "                select\n",
    "                    max(time at time zone 'GMT' at time zone 'America/Chicago') as time_\n",
    "                from\n",
    "                    main_production._completed_microbilt_iframe_\n",
    "                ) as latest_dates\n",
    "            \",\n",
    "            sep = ''\n",
    "        )\n",
    "    )$time_\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Heap to Funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns a final data frame that includes all the above status occurrence counts, grouped by DOY, DOW, and HOD.\n",
    "\n",
    "getDf = function(reporting.data, dl.data.raw, mb.data.raw) {\n",
    "    \n",
    "    dl.data = getAttemptAggregate(\n",
    "        data = dl.data.raw,\n",
    "        ibv.provider = 'DecisionLogic'\n",
    "    )\n",
    "    mb.data = getAttemptAggregate(\n",
    "        data = mb.data.raw,\n",
    "        ibv.provider = 'MicroBilt'\n",
    "    )\n",
    "    both.data = getAttemptAggregate(\n",
    "        data = getAttemptBothRaw(\n",
    "            dl.data.raw = dl.data.raw,\n",
    "            mb.data.raw = mb.data.raw\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    merged.data.dl = merge(\n",
    "        x = reporting.data,\n",
    "        y = dl.data,\n",
    "        by.x = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        by.y = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        all.x = TRUE\n",
    "    )\n",
    "    \n",
    "    merged.data.mb = merge(\n",
    "        x = merged.data.dl,\n",
    "        y = mb.data,\n",
    "        by.x = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        by.y = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        all.x = TRUE\n",
    "    )\n",
    "    \n",
    "    merged.data.both = merge(\n",
    "        x = merged.data.mb,\n",
    "        y = both.data,\n",
    "        by.x = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        by.y = c('dayofyear', 'dayofweek', 'hourofday', 'grouping'),\n",
    "        all.x = TRUE\n",
    "    )\n",
    "    \n",
    "#     merged.data.both$attempt.dl = ifelse(\n",
    "#         is.na(merged.data.both$attempt.dl),\n",
    "#         0,\n",
    "#         merged.data.both$attempt.dl\n",
    "#     )\n",
    "#     merged.data.both$attempt.mb = ifelse(\n",
    "#         is.na(merged.data.both$attempt.mb),\n",
    "#         0,\n",
    "#         merged.data.both$attempt.mb\n",
    "#     )\n",
    "#     merged.data.both$attempt.ibv = ifelse(\n",
    "#         is.na(merged.data.both$attempt.ibv),\n",
    "#         0,\n",
    "#         merged.data.both$attempt.ibv\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    return(merged.data.both)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This takes the overall data frame, and only keeps the numerator and denominator specified.\n",
    "## This also makes any un-refreshed data sources (usually Heap) and turns the NAs to 0.\n",
    "## Finally, attaches a column\n",
    "\n",
    "limitDf = function(data, numerator.string = NA, denominator.string = NA) {\n",
    "        \n",
    "    df = data[ , which(colnames(data) %in% c('dayofyear', 'dayofweek', 'hourofday', 'grouping', denominator.string, numerator.string))]\n",
    "    df.reorder = df[ , c(\n",
    "        which(colnames(df) == 'dayofyear'),\n",
    "        which(colnames(df) == 'dayofweek'),\n",
    "        which(colnames(df) == 'hourofday'),\n",
    "        which(colnames(df) == 'grouping'),\n",
    "        which(colnames(df) == denominator.string),\n",
    "        which(colnames(df) == numerator.string))]\n",
    "    \n",
    "    colnames(df.reorder) = c('dayofyear', 'dayofweek', 'hourofday', 'grouping', 'denominator', 'numerator')\n",
    "    \n",
    "    \n",
    "    df.reorder$denominator = ifelse(\n",
    "        is.na(df.reorder$denominator),\n",
    "        0,\n",
    "        df.reorder$denominator\n",
    "    )\n",
    "    df.reorder$numerator = ifelse(\n",
    "        is.na(df.reorder$numerator),\n",
    "        0,\n",
    "        df.reorder$numerator\n",
    "    )\n",
    "    \n",
    "    df.ordered = df.reorder[order(df.reorder$dayofyear, df.reorder$hourofday), ]\n",
    "    \n",
    "    \n",
    "    need.heap.tag.strings = c('attempt.dl', 'attempt.mb', 'attempt.ibv')\n",
    "    df.ordered.heap.tagged = data.frame(\n",
    "        df.ordered,\n",
    "        heap.time.tag = ifelse(\n",
    "            numerator.string %in% need.heap.tag.strings |\n",
    "            denominator.string %in% need.heap.tag.strings,\n",
    "            rep(1, nrow(df.ordered)),\n",
    "            rep(0, nrow(df.ordered))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return(df.ordered.heap.tagged)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove largest and smallest ratio for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## 2018-12-18 -- Wells Fargo DL Outage\n",
    "# ## 2018-12-20 -- Everything OK\n",
    "# ## 2010-01-01 -- Complete DL Outage\n",
    "# ## 2019-01-04 -- Chase DL Errors\n",
    "# ## 2019-01-05 -- Chase DL Errors\n",
    "# ## 2019-01-06 -- Chase DL Errors\n",
    "# ## 2019-01-07 -- Chase DL Errors\n",
    "# ## 2019-01-08 -- Chase DL Errors\n",
    "# ## 2019-01-13 -- NFCU DL Errors\n",
    "# ## 2019-01-17 -- Everything OK\n",
    "# ## 2019-01-18 -- Everything OK\n",
    "# ## 2019-01-19 -- Everything OK\n",
    "# ## 2019-01-20 -- Everything OK\n",
    "# ## 2019-01-21 -- Everything OK\n",
    "# ## 2019-01-22 -- Everything OK\n",
    "# # 2019-01-23 -- Everything OK\n",
    "# # 2019-01-29 -- Early DL Issues with Chase\n",
    "# 2019-02-07 -- Early DL Issues with Wells Fargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is to be used right before aggregation into DOW/HOD - after makeCumulative() when cumulative == TRUE.\n",
    "\n",
    "removeEdges = function (data.limited) {\n",
    "    \n",
    "    \n",
    "    bad.training.dates = as.Date(c('2018-12-12', '2019-01-01'))\n",
    "    \n",
    "    data.training = data.limited[which(data.limited$grouping == 'training' & !(data.limited$dayofyear %in% bad.training.dates)), ]\n",
    "    \n",
    "#     data.ratios = data.frame(\n",
    "#         data.training,\n",
    "#         ratio = ifelse(\n",
    "#             data.training$denominator != 0,\n",
    "#             data.training$numerator/data.training$denominator,\n",
    "#             0\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     data.minimum = data.ratios %>%\n",
    "#         group_by(\n",
    "#             dayofweek,\n",
    "#             hourofday\n",
    "#         ) %>%\n",
    "#         summarize(\n",
    "#             min.ratio = min(ratio)\n",
    "#         )\n",
    "    \n",
    "#     data.ratios.tagged = data.frame(\n",
    "#         data.ratios,\n",
    "#         is.min = ifelse(\n",
    "#             paste(data.ratios$dayofweek, data.ratios$hourofday, data.ratios$ratio) %in% paste(data.minimum$dayofweek, data.minimum$hourofday, data.minimum$min.ratio),\n",
    "#             1,\n",
    "#             0\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     data.no.minimum = data.ratios.tagged[which(data.ratios.tagged$is.min == 0), ]\n",
    "    \n",
    "#     return(data.no.minimum)\n",
    "    \n",
    "    return(data.training)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting -- Checks and Balances: Apps in Contract Signed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns the last known count of apps in status CONTRACT SIGNED in a dataframe.\n",
    "\n",
    "checkCS = function () {\n",
    "    dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        \"\n",
    "        select \n",
    "            max(createddate at time zone 'America/Chicago') as last_update\n",
    "            , count(case when status = 'CONTRACT SIGNED' then id end) as count_cs\n",
    "        from\n",
    "            cloudlending.applications\n",
    "        where\n",
    "            createddate >= now() - '15 days'::interval\n",
    "        \"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This returns the last known count of apps with owner UW QUEUE in a dataframe.\n",
    "\n",
    "checkUWQ = function () {\n",
    "    dbGetQuery(\n",
    "        createReportingConnectionObject(),\n",
    "        \"\n",
    "        select\n",
    "            max(createddate_) as last_update\n",
    "            , count(*) as count_uwq\n",
    "        from\n",
    "            (\n",
    "                select\n",
    "                    c_hist.parentid as application\n",
    "                    , c_hist.createddate at time zone 'America/Chicago' as createddate_\n",
    "                    , c_hist.newvalue\n",
    "                    , row_number() over (partition by c_hist.parentid order by c_hist.createddate desc) as rn\n",
    "                from\n",
    "                    cloudlending.applications_history as c_hist\n",
    "                    inner join\n",
    "                        cloudlending.applications as c_app\n",
    "                        on c_hist.parentid = c_app.id\n",
    "                where\n",
    "                    c_hist.field = 'Owner'\n",
    "                    and c_app.status not in ('DENIED', 'LOAN APPROVED')\n",
    "          ) as with_rn\n",
    "        where\n",
    "            rn = 1\n",
    "            and newvalue = '00G50000002rxZ4EAI'\n",
    "        \"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session // Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output list of DOY, DOW, HOURS.\n",
    "\n",
    "getSessionInfo = function(data) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    current.date = tail(\n",
    "        df$dayofyear,\n",
    "        1\n",
    "    )\n",
    "\n",
    "    current.day = tail(\n",
    "        df$dayofweek,\n",
    "        1\n",
    "    )\n",
    "\n",
    "    current.hours = seq(\n",
    "        from = 0,\n",
    "        to = 23,\n",
    "        by = 1\n",
    "    )\n",
    "\n",
    "    session.info = list(\n",
    "        date = current.date,\n",
    "        dow = current.day,\n",
    "        hours = current.hours\n",
    "    )\n",
    "    \n",
    "    return(session.info)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output aggregated (cumulative) data for TEST DATA.\n",
    "\n",
    "getSessionData = function(data, cumulative) {\n",
    "    \n",
    "    ## Create local variable on the parameter:DATA \n",
    "    df = data\n",
    "    df.session = df[which(df$grouping == 'test'), ]\n",
    "\n",
    "    \n",
    "    if (cumulative == TRUE) {\n",
    "        \n",
    "        session.point.estimates = \n",
    "            df.session %>%\n",
    "            group_by(\n",
    "                dayofyear\n",
    "            ) %>%\n",
    "    #         mutate(\n",
    "            transmute(\n",
    "                hourofday = hourofday,\n",
    "                denominator.session = cumsum(denominator),\n",
    "                numerator.session = cumsum(numerator),\n",
    "                ratio.session = ifelse(\n",
    "                    cumsum(denominator) > 0,\n",
    "                    cumsum(numerator)/cumsum(denominator),\n",
    "                    0\n",
    "                )\n",
    "            )\n",
    "    } else if (cumulative == FALSE) {\n",
    "        \n",
    "        session.point.estimates = \n",
    "        df.session %>%\n",
    "        group_by(\n",
    "            dayofyear,\n",
    "            hourofday\n",
    "        ) %>%\n",
    "        summarize(\n",
    "            denominator.session = sum(denominator),\n",
    "            numerator.session = sum(numerator),\n",
    "            ratio.session = ifelse(\n",
    "                sum(denominator) > 0,\n",
    "                sum(numerator)/sum(denominator),\n",
    "                0\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    if (max(df$heap.time.tag == 1)) {\n",
    "    \n",
    "        if (max(as.Date(df.session$dayofyear)) == Sys.Date()) {\n",
    "            \n",
    "            session.point.estimates$denominator.session[which(session.point.estimates$hourofday > hour(getLatestHeapRefresh()))] = 0\n",
    "            session.point.estimates$numerator.session[which(session.point.estimates$hourofday > hour(getLatestHeapRefresh()))] = 0\n",
    "            session.point.estimates$ratio.session[which(session.point.estimates$hourofday > hour(getLatestHeapRefresh()))] = 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return(session.point.estimates)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History // Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output mutated (cumulative) data for TRAINING DATA.\n",
    "## Reliant on getSessionInfo().\n",
    "\n",
    "makeCumulative = function(data) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    df.hist = df[which(df$grouping == 'training'), ]\n",
    "    \n",
    "    df.hist.mutate = \n",
    "        df.hist[which(df.hist$dayofweek == getSessionInfo(data = df)$dow), ] %>%\n",
    "        group_by(\n",
    "            dayofyear,\n",
    "            grouping\n",
    "        ) %>%\n",
    "        transmute(\n",
    "            dayofweek = dayofweek,\n",
    "            hourofday = hourofday,\n",
    "            denominator = cumsum(denominator),\n",
    "            numerator = cumsum(numerator)\n",
    "        )\n",
    "    \n",
    "    return(df.hist.mutate)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output aggregated (cumulative) data for TRAINING DATA.\n",
    "## Reliant on makeCumulative().\n",
    "\n",
    "getHistoricalData = function(data, cumulative) {\n",
    "    \n",
    "    ## Create local variable on the parameter:DATA     \n",
    "    df = data\n",
    "    \n",
    "    \n",
    "    if (cumulative == TRUE) {\n",
    "    \n",
    "        df.hist.mutate = removeEdges(makeCumulative(data = df))\n",
    "\n",
    "        historical.point.estimates = \n",
    "            df.hist.mutate %>%\n",
    "            group_by(\n",
    "                hourofday\n",
    "            ) %>%\n",
    "            summarize(\n",
    "                denominator.hist = sum(denominator),\n",
    "                numerator.hist = sum(numerator),\n",
    "                r.hist = sum(numerator)/sum(denominator),\n",
    "                n.hist = sum(denominator),\n",
    "                sd.denominator.hist = sd(denominator),\n",
    "                sd.numerator.hist = sd(numerator),\n",
    "                mu.denominator.hist = mean(denominator),\n",
    "                corr.hist = ifelse(is.na(cor(denominator, numerator)), 0, cor(denominator, numerator)),\n",
    "                se.hist = sqrt(\n",
    "                    (\n",
    "                        (\n",
    "                            sd(numerator)^2 + \n",
    "                            sd(denominator)^2 * (sum(numerator)/sum(denominator))^2 -\n",
    "                            2 * sum(numerator)/sum(denominator) * ifelse(is.na(cor(denominator, numerator)),0,cor(denominator, numerator)) * sd(numerator) * sd(denominator)\n",
    "                        ) /\n",
    "                        (\n",
    "                            sum(denominator) *\n",
    "                            mean(denominator)^2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    } else if (cumulative == FALSE) {\n",
    "\n",
    "        df.hist = removeEdges(df[which(df$grouping == 'training'), ])\n",
    "\n",
    "        historical.point.estimates = \n",
    "            df.hist[which(df.hist$dayofweek == getSessionInfo(data = df)$dow), ] %>%\n",
    "            group_by(\n",
    "                hourofday\n",
    "            ) %>%\n",
    "            summarize(\n",
    "                denominator.hist = sum(denominator),\n",
    "                numerator.hist = sum(numerator),\n",
    "                r.hist = sum(numerator)/sum(denominator),\n",
    "                n.hist = sum(denominator),\n",
    "                sd.denominator.hist = sd(denominator),\n",
    "                sd.numerator.hist = sd(numerator),\n",
    "                mu.denominator.hist = mean(denominator),\n",
    "                corr.hist = ifelse(is.na(cor(denominator, numerator)), 0, cor(denominator, numerator)),\n",
    "                se.hist = sqrt(\n",
    "                    (\n",
    "                        (\n",
    "                            sd(numerator)^2 + \n",
    "                            sd(denominator)^2 * (sum(numerator)/sum(denominator))^2 -\n",
    "                            2 * sum(numerator)/sum(denominator) * ifelse(is.na(cor(denominator, numerator)),0,cor(denominator, numerator)) * sd(numerator) * sd(denominator)\n",
    "                        ) /\n",
    "                        (\n",
    "                            sum(denominator) *\n",
    "                            mean(denominator)^2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    }\n",
    "\n",
    "    return(historical.point.estimates)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame.\n",
    "## Output Initialized CI data frame.\n",
    "## Reliant on getSessionDataCumulative() and getHistoricalDataCumulative().\n",
    "\n",
    "getInitialCI = function(data, cumulative) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    df.session = getSessionData(data = df, cumulative = cumulative)\n",
    "    df.historical = getHistoricalData(data = df, cumulative = cumulative)\n",
    "\n",
    "    ci.information = data.frame(\n",
    "\n",
    "        date.session = rep(max(as.Date(df.session$dayofyear)),24),\n",
    "        hour.session = df.historical$hourofday,\n",
    "        numerator.session = c(df.session$numerator.session, rep(0, 24 - length(df.session$numerator.session))),\n",
    "        denominator.session = c(df.session$denominator.session, rep(0, 24 - length(df.session$denominator.session))),\n",
    "        r.session = c(df.session$ratio.session, rep(0, 24 - length(df.session$ratio.session))),\n",
    "        r.hist = df.historical$r.hist,\n",
    "        se.hist = df.historical$se.hist,\n",
    "        z.lower = rep(0,24),\n",
    "        z.upper = rep(0,24),\n",
    "        ci.lower = rep(0,24),\n",
    "        ci.upper = rep(0,24)\n",
    "    )\n",
    "    \n",
    "    return(ci.information)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Input data frame and Bootstrap parameters.\n",
    "## Output Finalized CI data frame.\n",
    "## Reliant on getInitialCI() and makeCumulative().\n",
    "\n",
    "getBootstrapInterval = function(data, cumulative, B, alpha) {\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "#     ## Set Start Time.\n",
    "#     start_time = Sys.time()\n",
    "    \n",
    "    ## Initialize final output data frame.\n",
    "    ci.information = getInitialCI(data = df, cumulative = cumulative)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Initialize data for bootstrap.\n",
    "    if (cumulative == TRUE) {\n",
    "        \n",
    "        df.training.dow = makeCumulative(data = df)\n",
    "    } else if (cumulative == FALSE) {\n",
    "        \n",
    "        df.training = df[which(df$grouping == 'training'), ]\n",
    "        df.training.dow = df.training[which(df.training$dayofweek == getSessionInfo(data = df)$dow), ]\n",
    "    }\n",
    "    \n",
    "        \n",
    "    \n",
    "    ## Initialize container for bootstrap.\n",
    "    bootstrap_z = vector(length = B)\n",
    "    \n",
    "    ## Check for enough sample size\n",
    "#     histPDF = getHistoricalData(\n",
    "#         data = data,\n",
    "#         cumulative = FALSE\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    for (i in 1:24) {\n",
    "        \n",
    "#         if (histPDF$numerator.hist >= nrow(df.training.dow.hour) {\n",
    "\n",
    "            for (j in 1:B) {\n",
    "\n",
    "\n",
    "\n",
    "                ## Subset the data to the current HOD (i).\n",
    "                df.training.dow.hour = df.training.dow[which(df.training.dow$hourofday == i - 1), ]\n",
    "\n",
    "                index = seq(\n",
    "                    1, \n",
    "                    nrow(df.training.dow.hour)\n",
    "                )\n",
    "                resample_index = sample(\n",
    "                    x = index, \n",
    "                    size = length(index), \n",
    "                    replace = TRUE\n",
    "                )\n",
    "                df.training.dow.hour.resample = df.training.dow.hour[resample_index, ]\n",
    "\n",
    "\n",
    "                ## Calculate statistics from the resample.\n",
    "                r = sum(df.training.dow.hour.resample$numerator)/sum(df.training.dow.hour.resample$denominator)\n",
    "                n = sum(df.training.dow.hour.resample$denominator)\n",
    "                sx = sd(df.training.dow.hour.resample$denominator)\n",
    "                sy = sd(df.training.dow.hour.resample$numerator)\n",
    "                mx = mean(df.training.dow.hour.resample$denominator)\n",
    "                corr = ifelse(is.na(cor(df.training.dow.hour.resample$numerator, df.training.dow.hour.resample$denominator)),0,cor(df.training.dow.hour.resample$numerator, df.training.dow.hour.resample$denominator))\n",
    "\n",
    "                se = sqrt(\n",
    "                    (r^2*sx^2 + sy^2 - 2*r*corr*sx*sy)/\n",
    "                    (n*mx^2)\n",
    "                )\n",
    "\n",
    "\n",
    "                ## Calculate statistics from the training data.\n",
    "                mu = ci.information$r.hist[i]\n",
    "\n",
    "\n",
    "                ## Calculate the bootstrap Z\n",
    "                bootstrap_z[j] = (r - mu)/se\n",
    "            }\n",
    "#         }\n",
    "\n",
    "\n",
    "        ## For each hour, take Percentiles of the Bootstrap Z vector to caluclate the confidence interval for that hour.\n",
    "        bootstrap_z = sort(bootstrap_z)\n",
    "\n",
    "        ci.information$z.lower[i] = bootstrap_z[alpha/2*B]\n",
    "        ci.information$z.upper[i] = bootstrap_z[(1-alpha/2)*B]\n",
    "\n",
    "        ci.information$ci.lower = ci.information$r.hist - ci.information$z.upper * ci.information$se.hist\n",
    "        ci.information$ci.upper = ci.information$r.hist - ci.information$z.lower * ci.information$se.hist\n",
    "    }\n",
    "    \n",
    "    ci.information$ci.lower = ifelse(\n",
    "        is.na(ci.information$ci.lower),\n",
    "        0,\n",
    "        ci.information$ci.lower\n",
    "    )\n",
    "    \n",
    "    return(ci.information)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smoothLowerBound = function(ci.information, iterations) {\n",
    "    \n",
    "    ci.information.smooth = ci.information\n",
    "    \n",
    "    if (iterations >= 1) {\n",
    "    \n",
    "        for (i in 1:iterations) {\n",
    "\n",
    "            for (j in (0+1):(23-1)) {\n",
    "\n",
    "                ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)] = mean(\n",
    "                    c(ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)-1], ci.information.smooth$ci.lower[which(ci.information.smooth$hour.session == j)+1])\n",
    "                )\n",
    "            }        \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return(ci.information.smooth)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts column name to common name.\n",
    "\n",
    "getFunnelName = function(atStatus_string) {\n",
    "    \n",
    "    return_string = ''\n",
    "    \n",
    "    if (atStatus_string == 'qualified') {\n",
    "        return_string = 'Q'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt.ibv') {\n",
    "        return_string = 'Attempt IBV'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt.dl') {\n",
    "        return_string = 'Attempt DL'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt.mb') {\n",
    "        return_string = 'Attempt MB'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified') {\n",
    "        return_string = 'BV'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified.dl') {\n",
    "        return_string = 'Success DL'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified.mb') {\n",
    "        return_string = 'Success MB'\n",
    "    }\n",
    "    else if (atStatus_string == 'passscorecardratecard') {\n",
    "        return_string = 'SC'\n",
    "    }\n",
    "    else if (atStatus_string == 'contractsigned') {\n",
    "        return_string = 'CS'\n",
    "    }\n",
    "    else if (atStatus_string == 'cs_decisioned') {\n",
    "        return_string = 'CS Decisioned'\n",
    "    }\n",
    "    else if (atStatus_string == 'funded') {\n",
    "        return_string = 'F'\n",
    "    }\n",
    "    \n",
    "    return(return_string)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts column name to a specified color.\n",
    "\n",
    "getFunnelColor = function(atStatus_string) {\n",
    "    \n",
    "    color.decimal = ''\n",
    "\n",
    "    \n",
    "    if (atStatus_string == 'attempt.ibv') {\n",
    "        color.decimal = '#E76BF3'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt.dl') {\n",
    "        color.decimal = '#00BA38'\n",
    "    }\n",
    "    else if (atStatus_string == 'attempt.mb') {\n",
    "        color.decimal = '#FD61D1'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified.dl') {\n",
    "        color.decimal = '#00B0F6'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified.mb') {\n",
    "        color.decimal = '#E58700'\n",
    "    }\n",
    "    else if (atStatus_string == 'bankverified') {\n",
    "        color.decimal = '#619CFF'\n",
    "    }\n",
    "    else if (atStatus_string == 'passscorecardratecard') {\n",
    "        color.decimal = '#00C0AF'\n",
    "    }\n",
    "    else if (atStatus_string == 'contractsigned') {\n",
    "        color.decimal = '#B983FF'\n",
    "    }\n",
    "    else if (atStatus_string == 'cs_decisioned') {\n",
    "        color.decimal = '#C99800'\n",
    "    }\n",
    "    else if (atStatus_string == 'funded') {\n",
    "        color.decimal = '#619CFF'\n",
    "    }\n",
    "    \n",
    "    return(color.decimal)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns current states of CS and UWQ\n",
    "\n",
    "getSupportingTextPlot = function () {\n",
    "    \n",
    "    supporting.text = paste(\n",
    "        '\\n As of', checkCS()$last_update, 'there were', checkCS()$count_cs, 'apps that are in CONTRACT SIGNED. \\n\\n',\n",
    "        'As of', checkUWQ()$last_update, 'there were', checkUWQ()$count_uwq, 'apps that are in the UW Queue.'\n",
    "    )\n",
    "    \n",
    "    ggplot() + labs(caption = supporting.text) + theme(plot.caption = element_text(hjust = 0.5))\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getWarningBackground = function(bi.cumulative.true = NA, bi.cumulative.false = NA, numerator.string = NA, denominator.string = NA) {\n",
    "\n",
    "#     plot.funnel = paste(getFunnelName(numerator.string),'/',getFunnelName(denominator.string), sep = '')\n",
    "    \n",
    "#     reporting.refresh = getLatestReportingRefresh()\n",
    "#     heap.refresh = getLatestHeapRefresh()\n",
    "#     plot.hour.limit = ifelse(\n",
    "#         date(max(c(reporting.refresh, heap.refresh))) == Sys.Date(),\n",
    "#         ifelse(\n",
    "#             grepl('Attempt', plot.funnel), \n",
    "#             hour(getLatestHeapRefresh()), \n",
    "#             hour(getLatestReportingRefresh())\n",
    "#         ),\n",
    "#         23\n",
    "#     )\n",
    "\n",
    "    \n",
    "\n",
    "#     c.true.tagged = data.frame(\n",
    "#         bi.cumulative.true,\n",
    "#         is.zero = ifelse(bi.cumulative.true$r.session == 0, 1, 0),\n",
    "#         is.low = ifelse(bi.cumulative.true$r.session < bi.cumulative.true$ci.lower, 1, 0)\n",
    "#     )[which(bi.cumulative.true$hour.session < plot.hour.limit), ]\n",
    "\n",
    "#     c.true.warning = data.frame(\n",
    "#         c.true.tagged,\n",
    "#         rolling.zero.2 = c(rep(0,1), rollmean(x = c.true.tagged$is.zero, k = 2, align = 'left')),\n",
    "#         rolling.low.2 = c(rep(0,1), rollmean(x = c.true.tagged$is.low, k = 2, align = 'left')),\n",
    "#         rolling.low.3 = c(rep(0,2), rollmean(x = c.true.tagged$is.low, k = 3, align = 'left')),\n",
    "#         rolling.low.4 = c(rep(0,3), rollmean(x = c.true.tagged$is.low, k = 4, align = 'left')),\n",
    "#         rolling.low.5 = c(rep(0,4), rollmean(x = c.true.tagged$is.low, k = 5, align = 'left')),\n",
    "#         rolling.low.6 = c(rep(0,5), rollmean(x = c.true.tagged$is.low, k = 6, align = 'left'))\n",
    "#     )\n",
    "\n",
    "#     c.true.warning.return = ifelse(\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$is.zero == 1)) == 1 |\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$rolling.low.2 >= 1)) == 1 |\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$rolling.low.3 >= 2/3)) == 1 |\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$rolling.low.4 >= 3/4)) == 1 |\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$rolling.low.5 >= 3/5)) == 1 |\n",
    "#         max((c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18 & c.true.warning$rolling.low.6 >= 4/6)) == 1 |\n",
    "\n",
    "#         max((!(c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18) & c.true.warning$rolling.zero.2 == 1)) == 1 |\n",
    "#         max((!(c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18) & c.true.warning$rolling.low.4 >= 4/4)) == 1 |\n",
    "#         max((!(c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18) & c.true.warning$rolling.low.5 >= 4/5)) == 1 |\n",
    "#         max((!(c.true.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.true.warning$hour.session <= 18) & c.true.warning$rolling.low.6 >= 4/6)) == 1,\n",
    "#         1,\n",
    "#         0\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     c.false.tagged = data.frame(\n",
    "#         bi.cumulative.false,\n",
    "#         is.zero = ifelse(bi.cumulative.false$r.session == 0, 1, 0),\n",
    "#         is.low = ifelse(bi.cumulative.false$r.session < bi.cumulative.false$ci.lower, 1, 0)\n",
    "#     )[which(bi.cumulative.false$hour.session < plot.hour.limit), ]\n",
    "\n",
    "#     c.false.warning = data.frame(\n",
    "#         c.false.tagged,\n",
    "#         rolling.zero.2 = c(rep(0,1), rollmean(x = c.false.tagged$is.zero, k = 2, align = 'left')),\n",
    "#         rolling.low.2 = c(rep(0,1), rollmean(x = c.false.tagged$is.low, k = 2, align = 'left')),\n",
    "#         rolling.low.3 = c(rep(0,2), rollmean(x = c.false.tagged$is.low, k = 3, align = 'left')),\n",
    "#         rolling.low.4 = c(rep(0,3), rollmean(x = c.false.tagged$is.low, k = 4, align = 'left')),\n",
    "#         rolling.low.5 = c(rep(0,4), rollmean(x = c.false.tagged$is.low, k = 5, align = 'left')),\n",
    "#         rolling.low.6 = c(rep(0,5), rollmean(x = c.false.tagged$is.low, k = 6, align = 'left'))\n",
    "#     )\n",
    "\n",
    "#     c.false.warning.return = ifelse(\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$is.zero == 1)) == 1 |\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$rolling.low.2 >= 1)) == 1 |\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$rolling.low.3 >= 3/3)) == 1 |\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$rolling.low.4 >= 3/4)) == 1 |\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$rolling.low.5 >= 4/5)) == 1 |\n",
    "#         max((c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18 & c.false.warning$rolling.low.6 >= 4/6)) == 1 |\n",
    "\n",
    "#         max((!(c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18) & c.false.warning$rolling.zero.2 == 1)) == 1 |\n",
    "#         max((!(c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18) & c.false.warning$rolling.low.4 >= 4/4)) == 1 |\n",
    "#         max((!(c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18) & c.false.warning$rolling.low.5 >= 4/5)) == 1 |\n",
    "#         max((!(c.false.warning$hour.session >= ifelse(grepl('Decisioned', plot.funnel),9,7) & c.false.warning$hour.session <= 18) & c.false.warning$rolling.low.6 >= 4/6)) == 1,\n",
    "#         1,\n",
    "#         0\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     return(max(c.true.warning.return, c.false.warning.return))\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Returns Bootstrap plot.\n",
    "\n",
    "getBootstrapCowplot = function(data.limited, B, alpha, smooth.iterations, numerator.string = NA, denominator.string = NA) {\n",
    "    \n",
    "    df.bi.cumulative.true = smoothLowerBound( \n",
    "        ci.information = getBootstrapInterval(\n",
    "            data = data.limited,\n",
    "            cumulative = TRUE,\n",
    "            B = B,\n",
    "            alpha = alpha\n",
    "        ),\n",
    "        iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "    df.bi.cumulative.false = smoothLowerBound( \n",
    "        ci.information = getBootstrapInterval(\n",
    "            data = data.limited,\n",
    "            cumulative = FALSE,\n",
    "            B = B,\n",
    "            alpha = alpha\n",
    "        ),\n",
    "        iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "    #### Set plot details to be used in ggplot below.\n",
    "    \n",
    "\n",
    "            ## Plot Title - Identifier\n",
    "            plot.funnel = ifelse(\n",
    "                paste(getFunnelName(numerator.string),'/',getFunnelName(denominator.string), sep = '') == 'F/Q',\n",
    "                'Funding Rate',\n",
    "                paste(getFunnelName(numerator.string),'/',getFunnelName(denominator.string), sep = '')\n",
    "            )\n",
    "    \n",
    "            ## Plot Subtitle - Confidence Level\n",
    "            plot.alpha = paste(round(alpha*100,0), '%', sep = '')\n",
    "            \n",
    "            ## Plot Bars\n",
    "            plot.color = ifelse(\n",
    "                plot.funnel == 'Funding Rate',\n",
    "                '#FD61D1',\n",
    "                getFunnelColor(numerator.string)\n",
    "            )\n",
    "\n",
    "            ## Plot Caption - Volumes\n",
    "            plot.volume.check = paste(\n",
    "                getFunnelName(numerator.string), ': ', sum(df.bi.cumulative.false$numerator.session), ' // ',\n",
    "                getFunnelName(denominator.string), ': ', sum(df.bi.cumulative.false$denominator.session),'\\n',\n",
    "                sep = ''\n",
    "            )\n",
    "\n",
    "            ## Plot Caption - Volumes\n",
    "            if (grepl('Attempt', plot.funnel)) {\n",
    "                plot.refresh.check = getLatestHeapRefresh()\n",
    "            } else {\n",
    "                plot.refresh.check = getLatestReportingRefresh()\n",
    "            }\n",
    "            plot.refresh.check = paste('Last Data Update:', plot.refresh.check)\n",
    "    \n",
    "            ## Plot background\n",
    "#             plot.background = ifelse(\n",
    "#                 getWarningBackground(\n",
    "#                     bi.cumulative.true = df.bi.cumulative.true,\n",
    "#                     bi.cumulative.false = df.bi.cumulative.false,\n",
    "#                     numerator.string = numerator.string,\n",
    "#                     denominator.string = denominator.string\n",
    "#                 ) == 1, \n",
    "#                 'papayawhip', \n",
    "#                 'white'\n",
    "#             )\n",
    "    \n",
    "            \n",
    "    #### Call ggplot function - utilize if(cumulative == T/F){} for same function call -- for cowplot.\n",
    "    \n",
    "    plot.cumulative.true = ggplot(\n",
    "        data = df.bi.cumulative.true,\n",
    "        mapping = aes(\n",
    "            x = hour.session, \n",
    "            y = r.session\n",
    "        )        \n",
    "    ) +\n",
    "    geom_col(\n",
    "        fill = plot.color,\n",
    "        color = 'black'\n",
    "    ) + \n",
    "    labs(\n",
    "        y = '(Cumulative)', \n",
    "        title = paste(df.bi.cumulative.true$date.session, plot.funnel),\n",
    "        subtitle = paste('Line:', plot.alpha,'lower bound confidence interval of bars')\n",
    "    ) + \n",
    "    geom_line(\n",
    "        aes(\n",
    "            x = hour.session, \n",
    "            y = ci.lower\n",
    "        ), \n",
    "        color = 'black', \n",
    "        size=1.5\n",
    "    ) + \n",
    "    scale_y_continuous(\n",
    "        labels = scales::percent \n",
    "    ) + \n",
    "    scale_x_continuous(\n",
    "        breaks = seq(0,23,4)\n",
    "    ) +\n",
    "    theme(\n",
    "        plot.title = element_text(hjust = 0.5),\n",
    "        plot.subtitle = element_text(hjust = 0.5),\n",
    "        plot.margin = unit(c(0,0,0,0), 'cm'),\n",
    "        axis.title.x = element_blank()\n",
    "#         plot.background = element_rect(fill = plot.background)\n",
    "    ) \n",
    "    \n",
    "    \n",
    "    plot.cumulative.false = ggplot(\n",
    "        data = df.bi.cumulative.false,\n",
    "        mapping = aes(\n",
    "            x = hour.session, \n",
    "            y = r.session\n",
    "        )        \n",
    "    ) +\n",
    "    geom_col(\n",
    "        fill = plot.color,\n",
    "        color = 'black'\n",
    "    ) + \n",
    "    labs(\n",
    "        x = 'Hour of Day',\n",
    "        y = '(Not Cumulative)', \n",
    "        caption = paste(plot.volume.check, plot.refresh.check)\n",
    "    ) + \n",
    "    geom_line(\n",
    "        aes(\n",
    "            x = hour.session, \n",
    "            y = ci.lower\n",
    "        ), \n",
    "        color = 'black', \n",
    "        size=1.5\n",
    "    ) + \n",
    "    scale_y_continuous(\n",
    "        labels = scales::percent \n",
    "    ) + \n",
    "    scale_x_continuous(\n",
    "        breaks = seq(0,23,4)\n",
    "    ) +\n",
    "    theme(\n",
    "        plot.margin = unit(c(0,0,0,0), 'cm')\n",
    "#         plot.background = element_rect(fill = plot.background)\n",
    "    )\n",
    "    \n",
    "    df.plot = ggarrange(\n",
    "        plot.cumulative.true,\n",
    "        plot.cumulative.false,\n",
    "        align = 'v',\n",
    "        nrow = 2,\n",
    "        heights = c(3/5,2/5)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(df.plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create multiple ggplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getSalCowplots = function(data, B, alpha, smooth.iterations) {\n",
    "    \n",
    "    \n",
    "#     plot.1 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'bankverified',\n",
    "#             denominator.string = 'qualified'\n",
    "#         ),\n",
    "#         numerator.string = 'bankverified',\n",
    "#         denominator.string = 'qualified',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     )\n",
    "    \n",
    "\n",
    "#     plot.2 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'cs_decisioned',\n",
    "#             denominator.string = 'contractsigned'\n",
    "#         ),\n",
    "#         numerator.string = 'cs_decisioned',\n",
    "#         denominator.string = 'contractsigned',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     )\n",
    "    \n",
    "\n",
    "#     plot.3.1 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'attempt.dl',\n",
    "#             denominator.string = 'qualified'\n",
    "#         ),\n",
    "#         numerator.string = 'attempt.dl',\n",
    "#         denominator.string = 'qualified',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     )\n",
    "    \n",
    "\n",
    "#     plot.3.2 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'attempt.mb',\n",
    "#             denominator.string = 'qualified'\n",
    "#         ),\n",
    "#         numerator.string = 'attempt.mb',\n",
    "#         denominator.string = 'qualified',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     plot.4 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'bankverified.dl',\n",
    "#             denominator.string = 'attempt.dl'\n",
    "#         ),\n",
    "#         numerator.string = 'bankverified.dl',\n",
    "#         denominator.string = 'attempt.dl',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     ) \n",
    "\n",
    "#     plot.5 = getBootstrapCowplot(\n",
    "#         data.limited = limitDf(\n",
    "#             data = data,\n",
    "#             numerator.string = 'bankverified.mb',\n",
    "#             denominator.string = 'attempt.mb'\n",
    "#         ),\n",
    "#         numerator.string = 'bankverified.mb',\n",
    "#         denominator.string = 'attempt.mb',\n",
    "#         B = B,\n",
    "#         alpha = alpha,\n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     )  \n",
    "#     plot.support = getSupportingTextPlot()\n",
    "    \n",
    "#     all.plots = ggarrange(\n",
    "#         plot.1,\n",
    "#         plot.2,\n",
    "#         plot.3.1,\n",
    "#         plot.3.2,\n",
    "#         plot.4,\n",
    "#         plot.5,\n",
    "#         plot.support,\n",
    "#         ncol = 1\n",
    "#     )\n",
    " \n",
    "#     return(all.plots)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSalCowplots = function(data, B, alpha, smooth.iterations) {\n",
    "    \n",
    "    \n",
    "    plot.1 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'bankverified',\n",
    "            denominator.string = 'qualified'\n",
    "        ),\n",
    "        numerator.string = 'bankverified',\n",
    "        denominator.string = 'qualified',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "\n",
    "    plot.2 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'cs_decisioned',\n",
    "            denominator.string = 'contractsigned'\n",
    "        ),\n",
    "        numerator.string = 'cs_decisioned',\n",
    "        denominator.string = 'contractsigned',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "\n",
    "    plot.3.1 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'attempt.dl',\n",
    "            denominator.string = 'qualified'\n",
    "        ),\n",
    "        numerator.string = 'attempt.dl',\n",
    "        denominator.string = 'qualified',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "\n",
    "    plot.3.2 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'attempt.mb',\n",
    "            denominator.string = 'qualified'\n",
    "        ),\n",
    "        numerator.string = 'attempt.mb',\n",
    "        denominator.string = 'qualified',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "    \n",
    "    plot.4 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'bankverified.dl',\n",
    "            denominator.string = 'attempt.dl'\n",
    "        ),\n",
    "        numerator.string = 'bankverified.dl',\n",
    "        denominator.string = 'attempt.dl',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    ) \n",
    "\n",
    "    plot.5 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'bankverified.mb',\n",
    "            denominator.string = 'attempt.mb'\n",
    "        ),\n",
    "        numerator.string = 'bankverified.mb',\n",
    "        denominator.string = 'attempt.mb',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )  \n",
    "    \n",
    "\n",
    "    plot.6 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'passscorecardratecard',\n",
    "            denominator.string = 'bankverified'\n",
    "        ),\n",
    "        numerator.string = 'passscorecardratecard',\n",
    "        denominator.string = 'bankverified',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "    \n",
    "    \n",
    "    plot.7 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'contractsigned',\n",
    "            denominator.string = 'passscorecardratecard'\n",
    "        ),\n",
    "        numerator.string = 'contractsigned',\n",
    "        denominator.string = 'passscorecardratecard',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    ) \n",
    "\n",
    "    plot.8 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'cs_decisioned'\n",
    "        ),\n",
    "        numerator.string = 'funded',\n",
    "        denominator.string = 'cs_decisioned',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )  \n",
    "\n",
    "    plot.9 = getBootstrapCowplot(\n",
    "        data.limited = limitDf(\n",
    "            data = data,\n",
    "            numerator.string = 'funded',\n",
    "            denominator.string = 'qualified'\n",
    "        ),\n",
    "        numerator.string = 'funded',\n",
    "        denominator.string = 'qualified',\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )  \n",
    "    plot.support = getSupportingTextPlot()\n",
    "    \n",
    "    all.plots = ggarrange(\n",
    "        plot.9,\n",
    "        plot.1,\n",
    "        plot.3.1,\n",
    "        plot.3.2,\n",
    "        plot.4,\n",
    "        plot.5,\n",
    "        plot.6,\n",
    "        plot.7,\n",
    "        plot.2,\n",
    "        plot.8,\n",
    "        plot.support,\n",
    "        ncol = 1\n",
    "    )\n",
    " \n",
    "    return(all.plots)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export plots to PDF/PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VM\n",
    "exportSalCowplots = function (data, date.string, access.time, B, alpha, smooth.iterations) {\n",
    "    \n",
    "    options(warn = -1)\n",
    "    \n",
    "    getSalCowplots(\n",
    "        data = data,\n",
    "        B = B, \n",
    "        alpha = alpha, \n",
    "        smooth.iterations = smooth.iterations\n",
    "    ) %>%\n",
    "    ggexport(\n",
    "        filename = paste('C:/Users/jchang/Desktop/funnel-anomaly-detector-charts/', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-', '.png', sep = '')\n",
    "    )    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Laptop\n",
    "# exportSalCowplots = function (data, date.string, access.time, B, alpha, smooth.iterations) {\n",
    "    \n",
    "#     options(warn = -1)\n",
    "    \n",
    "#     getSalCowplots(\n",
    "#         data = data,\n",
    "#         B = B, \n",
    "#         alpha = alpha, \n",
    "#         smooth.iterations = smooth.iterations\n",
    "#     ) %>%\n",
    "#     ggexport(\n",
    "#         filename = paste('C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results/', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-', '.png', sep = '')\n",
    "#     )    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "executeExport = function(date.string, access.time, B = 100, alpha = 0.03, smooth.iterations = 1) {\n",
    "    \n",
    "    df = getDf(\n",
    "        reporting.data = getFunnel(date.string = date.string),\n",
    "        dl.data.raw = getAttemptDLRaw(date.string = date.string),\n",
    "        mb.data.raw = getAttemptMBRaw(date.string = date.string)\n",
    "    )\n",
    "    \n",
    "    exportSalCowplots(\n",
    "        data = df,\n",
    "        date.string = date.string,\n",
    "        access.time = access.time,\n",
    "        B = B,\n",
    "        alpha = alpha,\n",
    "        smooth.iterations = smooth.iterations\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate an Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VM\n",
    "getAttachmentString = function (date.string, access.time) {\n",
    "    \n",
    "    html.length = length(\n",
    "        list.files(\n",
    "            path = 'C:/Users/jchang/Desktop/funnel-anomaly-detector-charts',\n",
    "            pattern = paste('^', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), sep = '')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    if (html.length > 1) {\n",
    "\n",
    "        html.vector = paste(\n",
    "            rep(\n",
    "                '<img src = \"C:/Users/jchang/Desktop/funnel-anomaly-detector-charts/',\n",
    "                times = html.length\n",
    "            ),\n",
    "            rep(\n",
    "                x = paste(\n",
    "                    date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-', \n",
    "                    sep = ''\n",
    "                ),\n",
    "                times = html.length\n",
    "            ),\n",
    "            sprintf('%03d', c(1:html.length)),\n",
    "            rep(\n",
    "                x = '.png\">',\n",
    "                times = html.length\n",
    "            ),\n",
    "            sep = ''\n",
    "        )\n",
    "\n",
    "    } else if (html.length == 1) {\n",
    "\n",
    "        html.vector = paste(\n",
    "            '<img src = \"C:/Users/jchang/Desktop/funnel-anomaly-detector-charts/', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-.png\">', \n",
    "            sep = ''\n",
    "        )\n",
    "\n",
    "    } else {\n",
    "\n",
    "        html.vector = ''\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    html.string = paste(\n",
    "        html.vector,\n",
    "        collapse = ' '\n",
    "    )\n",
    "    \n",
    "    return(html.string)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Laptop\n",
    "# getAttachmentString = function (date.string, access.time) {\n",
    "    \n",
    "#     html.length = length(\n",
    "#         list.files(\n",
    "#             path = 'C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results',\n",
    "#             pattern = paste('^', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), sep = '')\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "    \n",
    "    \n",
    "#     if (html.length > 1) {\n",
    "\n",
    "#         html.vector = paste(\n",
    "#             rep(\n",
    "#                 '<img src = \"C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results/',\n",
    "#                 times = html.length\n",
    "#             ),\n",
    "#             rep(\n",
    "#                 x = paste(\n",
    "#                     date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-', \n",
    "#                     sep = ''\n",
    "#                 ),\n",
    "#                 times = html.length\n",
    "#             ),\n",
    "#             sprintf('%03d', c(1:html.length)),\n",
    "#             rep(\n",
    "#                 x = '.png\">',\n",
    "#                 times = html.length\n",
    "#             ),\n",
    "#             sep = ''\n",
    "#         )\n",
    "\n",
    "#     } else if (html.length == 1) {\n",
    "\n",
    "#         html.vector = paste(\n",
    "#             '<img src = \"C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results/', date.string, '-pulled-at-', date(access.time), '---', hour(access.time), '-', minute(access.time), '-.png\">', \n",
    "#             sep = ''\n",
    "#         )\n",
    "\n",
    "#     } else {\n",
    "\n",
    "#         html.vector = ''\n",
    "#     }\n",
    "\n",
    "    \n",
    "    \n",
    "#     html.string = paste(\n",
    "#         html.vector,\n",
    "#         collapse = ' '\n",
    "#     )\n",
    "    \n",
    "#     return(html.string)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "executeEmail = function (date.string = Sys.Date(), access.time = Sys.time()) {\n",
    "    \n",
    "    executeExport(\n",
    "        date.string = date.string,\n",
    "        access.time = access.time\n",
    "    )\n",
    "\n",
    "    sender = 'jchang@opploans.com'\n",
    "    recipients = c('jchang@opploans.com', 'tlongardner@opploans.com')\n",
    "    send.mail(\n",
    "        from = sender,\n",
    "        to = recipients,\n",
    "        subject = paste('Process Flow 7 IntraDay Report ---- ', month(date.string), '/', day(date.string), '/', year(date.string), ' at ', hour(access.time), ':', sprintf('%02d', minute(access.time)), sep = ''),\n",
    "        body = getAttachmentString(\n",
    "            date.string = date.string,\n",
    "            access.time = access.time\n",
    "        ),\n",
    "        html = TRUE,\n",
    "        inline = TRUE,\n",
    "        smtp = list(\n",
    "            host.name = 'smtp.gmail.com', \n",
    "            port = 465, \n",
    "            user.name = 'jchang@opploans.com',            \n",
    "            passwd = 'qgbwfocauwclvgnd', \n",
    "            ssl = TRUE\n",
    "        ),\n",
    "        authenticate = TRUE,\n",
    "        send = TRUE\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[[1]]\n",
      "<PostgreSQLConnection>\n",
      "\n",
      "[1] \"C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results/2019-03-20-pulled-at-2019-03-20---16-12-%03d.png\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file saved to C:/Users/jchang/Desktop/Projects/Funnel Anomaly Detection/results/2019-03-20-pulled-at-2019-03-20---16-12-%03d.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"Java-Object{org.apache.commons.mail.ImageHtmlEmail@3e9b1010}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 4.635733 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start = Sys.time()\n",
    "executeEmail(date.string = Sys.Date())\n",
    "\n",
    "# Sys.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = getFunnel('2019-03-20')\n",
    "# b = getAttemptDLRaw('2019-03-20')\n",
    "# c = getAttemptMBRaw('2019-03-20')\n",
    "# d = getDf(a,b,c)\n",
    "# executeExport(date.string = '2019-03-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
